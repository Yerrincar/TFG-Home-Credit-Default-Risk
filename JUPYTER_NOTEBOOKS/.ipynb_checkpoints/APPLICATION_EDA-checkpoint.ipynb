{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n",
      "Directorio actual: /home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS\n",
      "(307511, 122) (305811, 404) (305811, 23) (338857, 361) (337252, 37)\n"
     ]
    }
   ],
   "source": [
    "#Celda para librerías\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(np.__version__)\n",
    "from ydata_profiling import ProfileReport\n",
    "import os\n",
    "print(\"Directorio actual:\", os.getcwd())\n",
    "    \n",
    "# Have all columns appear when dataframes are displayed.\n",
    "pd.set_option('display.max_columns', None) \n",
    "# Have 100 rows appear when a dataframe is displayed\n",
    "pd.set_option('display.max_rows', 500)\n",
    "# Display dimensions whenever a dataframe is printed out.\n",
    "pd.set_option('display.show_dimensions', True)\n",
    "\n",
    "#Importando los datos\n",
    "\n",
    "app_train = pd.read_csv(r'/home/yeray/home-credit-default-risk/application_train.csv')\n",
    "app_test=pd.read_csv(r'/home/yeray/home-credit-default-risk/application_test.csv')\n",
    "app_test_pruebav1 = app_test.copy()\n",
    "bureau_final = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/bureau_agg_final.csv')\n",
    "bureau_balance__agg_def_v1 = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/bureau_balance_agg_def.csv')\n",
    "previous_application_agg = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/prev_app.csv')\n",
    "pos_cash_agg = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/pos_cash_agg_final.csv')\n",
    "installment_payment_agg = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/installment_payments_agg.csv')\n",
    "credit_card_balance = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/credit_card_balance_agg.csv')\n",
    "print(app_train.shape\n",
    "      , bureau_final.shape\n",
    "      , bureau_balance__agg_def_v1.shape\n",
    "      , previous_application_agg.shape\n",
    "      , pos_cash_agg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar los tipos de datos\n",
    "print(app_train['SK_ID_CURR'].dtype)\n",
    "print(bureau_final['SK_ID_CURR'].dtype)\n",
    "print(bureau_balance__agg_def_v1['SK_ID_CURR'].dtype)\n",
    "print(previous_application_agg['SK_ID_CURR'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 1120 entries, TARGET to HAS_CHILDREN\n",
      "dtypes: float64(1060), int64(41), object(19)\n",
      "memory usage: 2.6+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48744 entries, 0 to 48743\n",
      "Columns: 1120 entries, SK_ID_CURR to HAS_CHILDREN\n",
      "dtypes: float64(1060), int64(41), object(19)\n",
      "memory usage: 416.5+ MB\n",
      "None\n",
      "(48744, 1120)\n",
      "(307511, 1120)\n"
     ]
    }
   ],
   "source": [
    "#Uniendo los datos\n",
    "app_train = app_train.merge(bureau_final, on='SK_ID_CURR', how='left')\n",
    "app_train = app_train.merge(bureau_balance__agg_def_v1, on='SK_ID_CURR', how='left')\n",
    "app_train = app_train.merge(previous_application_agg, on='SK_ID_CURR', how='left')\n",
    "app_train = app_train.merge(pos_cash_agg, on='SK_ID_CURR', how='left')\n",
    "app_train = app_train.merge(installment_payment_agg, on='SK_ID_CURR', how='left')\n",
    "app_train = app_train.merge(credit_card_balance, on='SK_ID_CURR', how='left')\n",
    "######################\n",
    "# IMPLEMENTACIÓN \"A LO BRUTO\", NO ES LA MANERA CORRECTO, PERO QUIERO HACER ALGUNAS PRUEBAS. INVESTIGAR MÉTODOS DE HACERLO DE UNA FORMA MÁS EFICIENTE\n",
    "######################\n",
    "app_test_pruebav1 = app_test_pruebav1.merge(bureau_final, on='SK_ID_CURR', how='left')\n",
    "app_test_pruebav1 = app_test_pruebav1.merge(bureau_balance__agg_def_v1, on='SK_ID_CURR', how='left')\n",
    "app_test_pruebav1 = app_test_pruebav1.merge(previous_application_agg, on='SK_ID_CURR', how='left')\n",
    "app_test_pruebav1 = app_test_pruebav1.merge(pos_cash_agg, on='SK_ID_CURR', how='left')\n",
    "app_test_pruebav1 = app_test_pruebav1.merge(installment_payment_agg, on='SK_ID_CURR', how='left')\n",
    "app_test_pruebav1 = app_test_pruebav1.merge(credit_card_balance, on='SK_ID_CURR', how='left')\n",
    "#Para test\n",
    "app_test_pruebav1['AGE_INT'] = app_test_pruebav1['DAYS_BIRTH']/-365\n",
    "app_test_pruebav1['HAS_CHILDREN'] = np.where(app_test_pruebav1['CNT_CHILDREN'] > 0, 1, 0)                       \n",
    "\n",
    "app_train.drop(columns=['SK_ID_CURR'], inplace=True)\n",
    "#Debido a un fallo que detecta que todas los valores de la columna DAYS_BIRTH \n",
    "# son nan cuando no es así, vamos a sustituir la columna por una nueva llamada AGE_INT\n",
    "app_train['AGE_INT'] = app_train['DAYS_BIRTH']/-365\n",
    "app_train['HAS_CHILDREN'] = np.where(app_train['CNT_CHILDREN'] > 0, 1, 0)\n",
    "#variables_categoricas = app_train.select_dtypes(include=['object', 'category']).columns\n",
    "#app_train[variables_categoricas] = app_train[variables_categoricas].astype('category')\n",
    "#categoricas = variables_categoricas.tolist()\n",
    "info = app_train.info()\n",
    "print(info)\n",
    "print(app_test_pruebav1.info())\n",
    "#describe = app_train.describe()\n",
    "#print(describe)\n",
    "print(app_test_pruebav1.shape)\n",
    "print(app_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        100001\n",
      "1        100005\n",
      "2        100013\n",
      "3        100028\n",
      "4        100038\n",
      "          ...  \n",
      "48739    456221\n",
      "48740    456222\n",
      "48741    456223\n",
      "48742    456224\n",
      "48743    456250\n",
      "Name: SK_ID_CURR, Length: 48744, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['TARGET', 'CNT_CHILDREN', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
       "       'DAYS_ID_PUBLISH', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE',\n",
       "       'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'REGION_RATING_CLIENT',\n",
       "       'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START',\n",
       "       'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n",
       "       'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',\n",
       "       'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_2',\n",
       "       'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5',\n",
       "       'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8',\n",
       "       'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11',\n",
       "       'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14',\n",
       "       'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17',\n",
       "       'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20',\n",
       "       'FLAG_DOCUMENT_21', 'HAS_CHILDREN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(app_test_pruebav1['SK_ID_CURR'])\n",
    "app_train.select_dtypes(include=['int64']).columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "\n",
    "\n",
    "#Vamos a convertir la variable CNT_CHILDREN en una variable categórica que indique 1 si tiene hijos y 0 si no.\n",
    "\n",
    "#Vamos a crear la variable DAYS_EMPLOYED en una variable categórica que indique 1 si tiene empleo y 0 si no.\n",
    "app_train['HAS_EMPLOYMENT'] = app_train['DAYS_EMPLOYED'].map(lambda app_train: 1 if app_train < 0 else 0)\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "\n",
    "#Voy a crear RATIOS para algunas de las variables más importantes (en mi opinión y según lo investigado) \n",
    "# y que además tienen valores atípicos.\n",
    "app_train['CREDIT_AMT_INCOME_RATIO'] = app_train['AMT_CREDIT']/app_train['AMT_INCOME_TOTAL']\n",
    "app_train['CREDIT_AMT_INCOME_PORCENTAJE'] = app_train['AMT_INCOME_TOTAL']/app_train['AMT_CREDIT']\n",
    "\n",
    "app_train['ANNUITY_AMT_INCOME_RATIO'] = app_train['AMT_INCOME_TOTAL']/app_train['AMT_ANNUITY']\n",
    "app_train['ANNUITY_INCOME_PORCENTAJE'] = app_train['AMT_ANNUITY']/app_train['AMT_INCOME_TOTAL']\n",
    "\n",
    "app_train['GOODS_INCOME_RATIO'] = app_train['AMT_GOODS_PRICE']/app_train['AMT_INCOME_TOTAL']\n",
    "\n",
    "app_train['CREDIT_ANNUITY_RATIO'] = app_train['AMT_CREDIT']/app_train['AMT_ANNUITY']\n",
    "app_train['ANNUITY_CREDIT_PORCETAJE'] = app_train['AMT_ANNUITY']/app_train['AMT_CREDIT']\n",
    "app_train['CREDIT_GOODS_PRICE_RATIO'] = app_train['AMT_CREDIT']/app_train['AMT_GOODS_PRICE']\n",
    "\n",
    "app_train['ANNUITY_TO_DAYS_EMPLOYED_RATIO'] = app_train['AMT_ANNUITY']/app_train['DAYS_EMPLOYED']\n",
    "app_train['ANNUITY_TO_CHILDREN_RATIO'] = app_train['AMT_ANNUITY']/app_train['CNT_CHILDREN']\n",
    "\n",
    "app_train['INCOME_PER_CHILD'] = app_train['AMT_INCOME_TOTAL']/app_train['CNT_CHILDREN']\n",
    "app_train['CREDIT_PER_CHILD'] = app_train['AMT_CREDIT']/app_train['CNT_CHILDREN']\n",
    "\n",
    "app_train['AMT_INCOME_FAMILY_MEMBERS_RATIO'] = app_train['AMT_INCOME_TOTAL']/app_train['CNT_FAM_MEMBERS']\n",
    "app_train['CHILDREN_RATIO'] = app_train['CNT_CHILDREN']/app_train['CNT_FAM_MEMBERS']\n",
    "app_train['ADULTS_MEMBERS_DIFF'] = app_train['CNT_FAM_MEMBERS'] - app_train['CNT_CHILDREN']\n",
    "\n",
    "app_train['INCOME_PER_ADULT'] = app_train['AMT_INCOME_TOTAL']/app_train['ADULTS_MEMBERS_DIFF']\n",
    "app_train['CREDIT_PER_MEMBER'] = app_train['AMT_CREDIT']/app_train['CNT_FAM_MEMBERS']\n",
    "app_train['CREDIT_PER_ADULT'] = app_train['AMT_CREDIT']/app_train['ADULTS_MEMBERS_DIFF']\n",
    "app_train['ANNUITY_PER_ADULT'] = app_train['AMT_ANNUITY']/app_train['ADULTS_MEMBERS_DIFF']\n",
    "\n",
    "\n",
    "#app_train['OWN_CAR_AGE_RATIO'] = app_train['OWN_CAR_AGE']/app_train['AGE_INT']\n",
    "app_train['NEW_CAR_BIRTH_RATIO'] = app_train['OWN_CAR_AGE']/app_train['DAYS_BIRTH']\n",
    "app_train['NEW_CAR_EMPLOYMENT_RATIO'] = app_train['OWN_CAR_AGE']/app_train['DAYS_EMPLOYED']\n",
    "\n",
    "\n",
    "app_train['EMPLOYMENT_AGE_RATIO'] = app_train['DAYS_EMPLOYED']/-app_train['AGE_INT']\n",
    "#app_train['EMPLOYMENT_BIRTH_RATIO'] = app_train['DAYS_EMPLOYED']/app_train['DAYS_BIRTH']\n",
    "app_train['EMPLOYMENT_PHONE_CHANGE_RATIO'] = app_train['DAYS_LAST_PHONE_CHANGE']/app_train['DAYS_EMPLOYED']\n",
    "\n",
    "app_train['NEW_PHONE_CHANGE_BIRTH_RATIO'] = app_train['DAYS_LAST_PHONE_CHANGE']/app_train['DAYS_BIRTH']\n",
    "app_train['NEW_PHONE_CHANGE_EMPLOYMENT_RATIO'] = app_train['DAYS_LAST_PHONE_CHANGE']/app_train['DAYS_EMPLOYED']\n",
    "app_train['DAYS_ID_PUBLISH_BIRTH_RAIO'] = app_train['DAYS_ID_PUBLISH']/app_train['DAYS_BIRTH']\n",
    "\n",
    "app_train['REGISTRATION_TO_NEW_PHONE_CHANGE_RATIO'] = app_train['DAYS_LAST_PHONE_CHANGE']/app_train['DAYS_REGISTRATION']\n",
    "#app_train['REGISTRATION_TO_ID_PUBLISH_RATIO'] = app_train['DAYS_ID_PUBLISH'] - app_train['DAYS_REGISTRATION']\n",
    "#app_train['REGISTRATION_TO_BIRTH_RATIO'] = app_train['DAYS_BIRTH'] - app_train['DAYS_REGISTRATION']\n",
    "\n",
    "#EXT_SOURCE son variables representan fuentes externas de información sobre el cliente, y suelen estar relacionadas con puntuaciones de riesgo crediticio generadas por \n",
    "# instituciones externas al prestamista, como burós de crédito u otras entidades que evalúan el perfil financiero de los clientes.\n",
    "#Vamos a crear variables relacionadas con EXT_SOURCE.\n",
    "\n",
    "app_train['EXT_SOURCE_SUM'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis=1)\n",
    "app_train['EXT_SOURCE_MEAN'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "app_train['EXT_SOURCE_MEDIAN'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].median(axis=1)\n",
    "app_train['EXT_SOURCE_MAX'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].max(axis=1)\n",
    "app_train['EXT_SOURCE_MIN'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].min(axis=1)\n",
    "\n",
    "app_train['EXT_SOURCE_WEIGHTED_SUM'] = app_train['EXT_SOURCE_1']*3 + app_train['EXT_SOURCE_2']*1 + app_train['EXT_SOURCE_3']*5\n",
    "app_train['EXT_SOURCE_WEIGHTED_MEAN'] = (app_train['EXT_SOURCE_1']*3 + app_train['EXT_SOURCE_2']*1 + app_train['EXT_SOURCE_3']*5)/3\n",
    "app_train['EXT_SOURCE_PROD'] = app_train['EXT_SOURCE_1']*app_train['EXT_SOURCE_2']*app_train['EXT_SOURCE_3']\n",
    "\n",
    "app_train['RATIO_EXT_SOURCE_3_TO_REGION_POPULATION_RELATIVE'] = app_train['EXT_SOURCE_3'] / app_train['REGION_POPULATION_RELATIVE']\n",
    "\n",
    "\"\"\"\n",
    "app_train['AGE_CREDIT_RATIO'] = app_train['AGE_INT']/app_train['AMT_CREDIT']\n",
    "app_train['AGE_ANNUITY_RATIO'] = app_train['AGE_INT']/app_train['AMT_ANNUITY']\n",
    "app_train['AGE_GOODS_PRICE_RATIO'] = app_train['AGE_INT']/app_train['AMT_GOODS_PRICE']\n",
    "app_train['AGE_INCOME_RATIO'] = app_train['AGE_INT']/app_train['AMT_INCOME_TOTAL']\n",
    "\"\"\"\n",
    "app_train['AGE_CREDIT_RATIO'] = app_train['AMT_CREDIT']/app_train['DAYS_BIRTH']\n",
    "app_train['AGE_ANNUITY_RATIO'] = app_train['AMT_ANNUITY']/app_train['DAYS_BIRTH']\n",
    "app_train['AGE_GOODS_PRICE_RATIO'] = app_train['AMT_GOODS_PRICE']/app_train['DAYS_BIRTH']\n",
    "app_train['AGE_INCOME_RATIO'] = app_train['AMT_INCOME_TOTAL']/app_train['DAYS_BIRTH']\n",
    "\n",
    "\n",
    "\n",
    "#Variables a partir de sumas y diferencias\n",
    "app_train['AMT_INCOME_TOTAL_ANNUITY_SUM'] = app_train['AMT_INCOME_TOTAL'] + app_train['AMT_ANNUITY']\n",
    "app_train['AMT_GOODS_TO_INCOME_ANUITY_SUM_RATIO'] = app_train['AMT_GOODS_PRICE']/(app_train['AMT_INCOME_TOTAL_ANNUITY_SUM'] )\n",
    "app_train['CREDIT_BUREAU_TOTAL'] = app_train[['AMT_REQ_CREDIT_BUREAU_DAY', \n",
    "                                             'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "                                             'AMT_REQ_CREDIT_BUREAU_MON',\n",
    "                                             'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "                                             'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "                                             'AMT_REQ_CREDIT_BUREAU_YEAR']].sum(axis=1)\n",
    "\n",
    "app_train['CREDIT_GOODS_DIFF'] = app_train['AMT_GOODS_PRICE'] - app_train['AMT_CREDIT']\n",
    "app_train['GOODS_ANNUITY_DIFF'] = app_train['AMT_ANNUITY'] - app_train['AMT_GOODS_PRICE']\n",
    "app_train['AMT_INCOME_TOTAL_ANNUITY_DIFF'] = app_train['AMT_INCOME_TOTAL'] - app_train['AMT_ANNUITY']\n",
    "\n",
    "#app_train['SOCIAL_OBSERVATION_TOTAL'] = app_train['OBS_30_CNT_SOCIAL_CIRCLE'] + app_train['OBS_60_CNT_SOCIAL_CIRCLE']\n",
    "#app_train['SOCIAL_DEF_TOTAL'] = app_train['DEF_30_CNT_SOCIAL_CIRCLE'] + app_train['DEF_60_CNT_SOCIAL_CIRCLE']\n",
    "\n",
    "app_train['DIFF_OBS_30_60'] = app_train['OBS_30_CNT_SOCIAL_CIRCLE'] - app_train['OBS_60_CNT_SOCIAL_CIRCLE']\n",
    "app_train['DIFF_DEF_30_60'] = app_train['DEF_30_CNT_SOCIAL_CIRCLE'] - app_train['DEF_60_CNT_SOCIAL_CIRCLE'] \n",
    "\n",
    "app_train['LONG_EMPLOYMENT'] = np.where(app_train['DAYS_EMPLOYED'] < -2000, 1, 0)\n",
    "app_train['RETIRED'] = np.where(app_train['DAYS_BIRTH'] < -14000, 1, 0)\n",
    "\n",
    "#OTRAS\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Feature Engineering para app_test_pruebav1 --\n",
    "\n",
    "# Vamos a convertir la variable CNT_CHILDREN en una variable categórica que indique 1 si tiene hijos y 0 si no.\n",
    "# (Ya hiciste algo parecido en la creación de la columna HAS_CHILDREN, \n",
    "#  si lo necesitas nuevamente, lo mantienes. De lo contrario, omítelo.)\n",
    "\n",
    "# Vamos a crear la variable DAYS_EMPLOYED en una variable categórica que indique 1 si tiene empleo y 0 si no.\n",
    "app_test_pruebav1['HAS_EMPLOYMENT'] = app_test_pruebav1['DAYS_EMPLOYED'].map(lambda x: 1 if x < 0 else 0)\n",
    "app_test_pruebav1['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "# Creación de RATIOS\n",
    "app_test_pruebav1['CREDIT_AMT_INCOME_RATIO'] = app_test_pruebav1['AMT_CREDIT'] / app_test_pruebav1['AMT_INCOME_TOTAL']\n",
    "app_test_pruebav1['CREDIT_AMT_INCOME_PORCENTAJE'] = app_test_pruebav1['AMT_INCOME_TOTAL'] / app_test_pruebav1['AMT_CREDIT']\n",
    "\n",
    "app_test_pruebav1['ANNUITY_AMT_INCOME_RATIO'] = app_test_pruebav1['AMT_INCOME_TOTAL'] / app_test_pruebav1['AMT_ANNUITY']\n",
    "app_test_pruebav1['ANNUITY_INCOME_PORCENTAJE'] = app_test_pruebav1['AMT_ANNUITY'] / app_test_pruebav1['AMT_INCOME_TOTAL']\n",
    "\n",
    "app_test_pruebav1['GOODS_INCOME_RATIO'] = app_test_pruebav1['AMT_GOODS_PRICE'] / app_test_pruebav1['AMT_INCOME_TOTAL']\n",
    "\n",
    "app_test_pruebav1['CREDIT_ANNUITY_RATIO'] = app_test_pruebav1['AMT_CREDIT'] / app_test_pruebav1['AMT_ANNUITY']\n",
    "app_test_pruebav1['ANNUITY_CREDIT_PORCETAJE'] = app_test_pruebav1['AMT_ANNUITY'] / app_test_pruebav1['AMT_CREDIT']\n",
    "app_test_pruebav1['CREDIT_GOODS_PRICE_RATIO'] = app_test_pruebav1['AMT_CREDIT'] / app_test_pruebav1['AMT_GOODS_PRICE']\n",
    "\n",
    "app_test_pruebav1['ANNUITY_TO_DAYS_EMPLOYED_RATIO'] = app_test_pruebav1['AMT_ANNUITY'] / app_test_pruebav1['DAYS_EMPLOYED']\n",
    "app_test_pruebav1['ANNUITY_TO_CHILDREN_RATIO'] = app_test_pruebav1['AMT_ANNUITY'] / app_test_pruebav1['CNT_CHILDREN']\n",
    "\n",
    "app_test_pruebav1['INCOME_PER_CHILD'] = app_test_pruebav1['AMT_INCOME_TOTAL'] / app_test_pruebav1['CNT_CHILDREN']\n",
    "app_test_pruebav1['CREDIT_PER_CHILD'] = app_test_pruebav1['AMT_CREDIT'] / app_test_pruebav1['CNT_CHILDREN']\n",
    "\n",
    "app_test_pruebav1['AMT_INCOME_FAMILY_MEMBERS_RATIO'] = app_test_pruebav1['AMT_INCOME_TOTAL'] / app_test_pruebav1['CNT_FAM_MEMBERS']\n",
    "app_test_pruebav1['CHILDREN_RATIO'] = app_test_pruebav1['CNT_CHILDREN'] / app_test_pruebav1['CNT_FAM_MEMBERS']\n",
    "app_test_pruebav1['ADULTS_MEMBERS_DIFF'] = app_test_pruebav1['CNT_FAM_MEMBERS'] - app_test_pruebav1['CNT_CHILDREN']\n",
    "\n",
    "app_test_pruebav1['INCOME_PER_ADULT'] = app_test_pruebav1['AMT_INCOME_TOTAL'] / app_test_pruebav1['ADULTS_MEMBERS_DIFF']\n",
    "app_test_pruebav1['CREDIT_PER_MEMBER'] = app_test_pruebav1['AMT_CREDIT'] / app_test_pruebav1['CNT_FAM_MEMBERS']\n",
    "app_test_pruebav1['CREDIT_PER_ADULT'] = app_test_pruebav1['AMT_CREDIT'] / app_test_pruebav1['ADULTS_MEMBERS_DIFF']\n",
    "app_test_pruebav1['ANNUITY_PER_ADULT'] = app_test_pruebav1['AMT_ANNUITY'] / app_test_pruebav1['ADULTS_MEMBERS_DIFF']\n",
    "\n",
    "# app_test_pruebav1['OWN_CAR_AGE_RATIO'] = app_test_pruebav1['OWN_CAR_AGE'] / app_test_pruebav1['AGE_INT']\n",
    "app_test_pruebav1['NEW_CAR_BIRTH_RATIO'] = app_test_pruebav1['OWN_CAR_AGE'] / app_test_pruebav1['DAYS_BIRTH']\n",
    "app_test_pruebav1['NEW_CAR_EMPLOYMENT_RATIO'] = app_test_pruebav1['OWN_CAR_AGE'] / app_test_pruebav1['DAYS_EMPLOYED']\n",
    "\n",
    "app_test_pruebav1['EMPLOYMENT_AGE_RATIO'] = app_test_pruebav1['DAYS_EMPLOYED'] / -app_test_pruebav1['AGE_INT']\n",
    "#app_test_pruebav1['EMPLOYMENT_BIRTH_RATIO'] = app_test_pruebav1['DAYS_EMPLOYED'] / app_test_pruebav1['DAYS_BIRTH']\n",
    "app_test_pruebav1['EMPLOYMENT_PHONE_CHANGE_RATIO'] = app_test_pruebav1['DAYS_LAST_PHONE_CHANGE'] / app_test_pruebav1['DAYS_EMPLOYED']\n",
    "\n",
    "app_test_pruebav1['NEW_PHONE_CHANGE_BIRTH_RATIO'] = app_test_pruebav1['DAYS_LAST_PHONE_CHANGE'] / app_test_pruebav1['DAYS_BIRTH']\n",
    "app_test_pruebav1['NEW_PHONE_CHANGE_EMPLOYMENT_RATIO'] = app_test_pruebav1['DAYS_LAST_PHONE_CHANGE'] / app_test_pruebav1['DAYS_EMPLOYED']\n",
    "app_test_pruebav1['DAYS_ID_PUBLISH_BIRTH_RAIO'] = app_test_pruebav1['DAYS_ID_PUBLISH'] / app_test_pruebav1['DAYS_BIRTH']\n",
    "\n",
    "app_test_pruebav1['REGISTRATION_TO_NEW_PHONE_CHANGE_RATIO'] = app_test_pruebav1['DAYS_LAST_PHONE_CHANGE'] / app_test_pruebav1['DAYS_REGISTRATION']\n",
    "#app_test_pruebav1['REGISTRATION_TO_ID_PUBLISH_RATIO'] = app_test_pruebav1['DAYS_ID_PUBLISH'] - app_test_pruebav1['DAYS_REGISTRATION']\n",
    "#app_test_pruebav1['REGISTRATION_TO_BIRTH_RATIO'] = app_test_pruebav1['DAYS_BIRTH'] - app_test_pruebav1['DAYS_REGISTRATION']\n",
    "\n",
    "#EXT_SOURCE => creamos variables relacionadas con EXT_SOURCE_1,2,3\n",
    "app_test_pruebav1['EXT_SOURCE_SUM'] = app_test_pruebav1[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis=1)\n",
    "app_test_pruebav1['EXT_SOURCE_MEAN'] = app_test_pruebav1[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "app_test_pruebav1['EXT_SOURCE_MEDIAN'] = app_test_pruebav1[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].median(axis=1)\n",
    "app_test_pruebav1['EXT_SOURCE_MAX'] = app_test_pruebav1[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].max(axis=1)\n",
    "app_test_pruebav1['EXT_SOURCE_MIN'] = app_test_pruebav1[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].min(axis=1)\n",
    "\n",
    "app_test_pruebav1['EXT_SOURCE_WEIGHTED_SUM'] = (\n",
    "    app_test_pruebav1['EXT_SOURCE_1'] * 3\n",
    "  + app_test_pruebav1['EXT_SOURCE_2'] * 1\n",
    "  + app_test_pruebav1['EXT_SOURCE_3'] * 5\n",
    ")\n",
    "app_test_pruebav1['EXT_SOURCE_WEIGHTED_MEAN'] = (\n",
    "    (app_test_pruebav1['EXT_SOURCE_1'] * 3\n",
    "    + app_test_pruebav1['EXT_SOURCE_2'] * 1\n",
    "    + app_test_pruebav1['EXT_SOURCE_3'] * 5) / 3\n",
    ")\n",
    "app_test_pruebav1['EXT_SOURCE_PROD'] = (\n",
    "    app_test_pruebav1['EXT_SOURCE_1']\n",
    "  * app_test_pruebav1['EXT_SOURCE_2']\n",
    "  * app_test_pruebav1['EXT_SOURCE_3']\n",
    ")\n",
    "\n",
    "app_test_pruebav1['RATIO_EXT_SOURCE_3_TO_REGION_POPULATION_RELATIVE'] = (\n",
    "    app_test_pruebav1['EXT_SOURCE_3'] / app_test_pruebav1['REGION_POPULATION_RELATIVE']\n",
    ")\n",
    "\n",
    "# Ejemplo en comentarios: la inversa\n",
    "app_test_pruebav1['AGE_CREDIT_RATIO'] = app_test_pruebav1['AMT_CREDIT'] / app_test_pruebav1['DAYS_BIRTH']\n",
    "app_test_pruebav1['AGE_ANNUITY_RATIO'] = app_test_pruebav1['AMT_ANNUITY'] / app_test_pruebav1['DAYS_BIRTH']\n",
    "app_test_pruebav1['AGE_GOODS_PRICE_RATIO'] = app_test_pruebav1['AMT_GOODS_PRICE'] / app_test_pruebav1['DAYS_BIRTH']\n",
    "app_test_pruebav1['AGE_INCOME_RATIO'] = app_test_pruebav1['AMT_INCOME_TOTAL'] / app_test_pruebav1['DAYS_BIRTH']\n",
    "\n",
    "#Variables a partir de sumas y diferencias\n",
    "app_test_pruebav1['AMT_INCOME_TOTAL_ANNUITY_SUM'] = (\n",
    "    app_test_pruebav1['AMT_INCOME_TOTAL'] + app_test_pruebav1['AMT_ANNUITY']\n",
    ")\n",
    "app_test_pruebav1['AMT_GOODS_TO_INCOME_ANUITY_SUM_RATIO'] = (\n",
    "    app_test_pruebav1['AMT_GOODS_PRICE'] / app_test_pruebav1['AMT_INCOME_TOTAL_ANNUITY_SUM']\n",
    ")\n",
    "app_test_pruebav1['CREDIT_BUREAU_TOTAL'] = app_test_pruebav1[[\n",
    "    'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "    'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "    'AMT_REQ_CREDIT_BUREAU_MON',\n",
    "    'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "    'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "    'AMT_REQ_CREDIT_BUREAU_YEAR'\n",
    "]].sum(axis=1)\n",
    "\n",
    "app_test_pruebav1['CREDIT_GOODS_DIFF'] = app_test_pruebav1['AMT_GOODS_PRICE'] - app_test_pruebav1['AMT_CREDIT']\n",
    "app_test_pruebav1['GOODS_ANNUITY_DIFF'] = app_test_pruebav1['AMT_ANNUITY'] - app_test_pruebav1['AMT_GOODS_PRICE']\n",
    "app_test_pruebav1['AMT_INCOME_TOTAL_ANNUITY_DIFF'] = (\n",
    "    app_test_pruebav1['AMT_INCOME_TOTAL'] - app_test_pruebav1['AMT_ANNUITY']\n",
    ")\n",
    "\n",
    "# app_test_pruebav1['SOCIAL_OBSERVATION_TOTAL'] = ...\n",
    "# app_test_pruebav1['SOCIAL_DEF_TOTAL'] = ...\n",
    "\n",
    "app_test_pruebav1['DIFF_OBS_30_60'] = (\n",
    "    app_test_pruebav1['OBS_30_CNT_SOCIAL_CIRCLE'] - app_test_pruebav1['OBS_60_CNT_SOCIAL_CIRCLE']\n",
    ")\n",
    "app_test_pruebav1['DIFF_DEF_30_60'] = (\n",
    "    app_test_pruebav1['DEF_30_CNT_SOCIAL_CIRCLE'] - app_test_pruebav1['DEF_60_CNT_SOCIAL_CIRCLE']\n",
    ")\n",
    "\n",
    "app_test_pruebav1['LONG_EMPLOYMENT'] = np.where(app_test_pruebav1['DAYS_EMPLOYED'] < -2000, 1, 0)\n",
    "app_test_pruebav1['RETIRED'] = np.where(app_test_pruebav1['DAYS_BIRTH'] < -14000, 1, 0)\n",
    "\n",
    "# (Si no hay más)\n",
    "# Fin de las \"OTRAS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        100001\n",
      "1        100005\n",
      "2        100013\n",
      "3        100028\n",
      "4        100038\n",
      "          ...  \n",
      "48739    456221\n",
      "48740    456222\n",
      "48741    456223\n",
      "48742    456224\n",
      "48743    456250\n",
      "Name: SK_ID_CURR, Length: 48744, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(app_test_pruebav1['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    307511.000000\n",
      "mean          2.509507\n",
      "std           0.874544\n",
      "min           1.000000\n",
      "25%           2.000000\n",
      "50%           2.000000\n",
      "75%           3.000000\n",
      "max           5.000000\n",
      "Name: EDUCATION_LEVEL, Length: 8, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nincome_type_mapping = {\\n    'Unemployed': 0,\\n    'Student': 1,\\n    'Pensioner': 2,\\n    'Maternity leave': 3,\\n    'Working': 4,\\n    'State servant': 5,\\n    'Commercial associate': 6,\\n    'Businessman': 7,    \\n}\\napp_train['INCOME_TYPE'] = app_train['NAME_INCOME_TYPE'].map(income_type_mapping)\\n\\nfamily_mapping = {\\n    'Single / not married': 0,\\n    'Separated': 1,\\n    'Widow': 2,\\n    'Married': 3\\n}\\n\\nhousing_mapping = {\\n    'With parents': 0,\\n    'Municipal apartment': 1,\\n    'Rented apartment': 2,\\n    'House / apartment': 3\\n}\\n\\n\\n\\napp_train['FAMILY_STATUS'] = app_train['NAME_FAMILY_STATUS'].map(family_mapping)\\napp_train['HOUSING_TYPE'] = app_train['NAME_HOUSING_TYPE'].map(housing_mapping)\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_mapping = {\n",
    "    'No formal education': 0,\n",
    "    'Lower secondary': 1,\n",
    "    'Secondary / secondary special': 2,\n",
    "    'Incomplete higher': 3,\n",
    "    'Higher education': 4,\n",
    "    'Academic degree': 5\n",
    "}\n",
    "\n",
    "app_train['EDUCATION_LEVEL'] = app_train['NAME_EDUCATION_TYPE'].map(education_mapping)\n",
    "app_test_pruebav1['EDUCATION_LEVEL'] = app_test_pruebav1['NAME_EDUCATION_TYPE'].map(education_mapping)\n",
    "print(app_train['EDUCATION_LEVEL'].describe())\n",
    "\"\"\"\n",
    "income_type_mapping = {\n",
    "    'Unemployed': 0,\n",
    "    'Student': 1,\n",
    "    'Pensioner': 2,\n",
    "    'Maternity leave': 3,\n",
    "    'Working': 4,\n",
    "    'State servant': 5,\n",
    "    'Commercial associate': 6,\n",
    "    'Businessman': 7,    \n",
    "}\n",
    "app_train['INCOME_TYPE'] = app_train['NAME_INCOME_TYPE'].map(income_type_mapping)\n",
    "\n",
    "family_mapping = {\n",
    "    'Single / not married': 0,\n",
    "    'Separated': 1,\n",
    "    'Widow': 2,\n",
    "    'Married': 3\n",
    "}\n",
    "\n",
    "housing_mapping = {\n",
    "    'With parents': 0,\n",
    "    'Municipal apartment': 1,\n",
    "    'Rented apartment': 2,\n",
    "    'House / apartment': 3\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "app_train['FAMILY_STATUS'] = app_train['NAME_FAMILY_STATUS'].map(family_mapping)\n",
    "app_train['HOUSING_TYPE'] = app_train['NAME_HOUSING_TYPE'].map(housing_mapping)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662f4a552995474a8c90dce1a7f79da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86c7393355b44f08796344a6293698f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fc5a8882544dc8ab61862cfff817e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51dcc7ab27d74f35833c597372295811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AGREGACIONES\n",
    "agregaciones = [\n",
    "    (['CODE_GENDER', 'NAME_EDUCATION_TYPE'], [('AMT_ANNUITY', 'max'),\n",
    "                                              ('AMT_CREDIT', 'max'),\n",
    "                                              ('EXT_SOURCE_1', 'mean'),\n",
    "                                              ('EXT_SOURCE_2', 'mean'),\n",
    "                                              ('EXT_SOURCE_3', 'mean'),\n",
    "                                              ('AGE_INT', 'mean'),\n",
    "                                              ('OWN_CAR_AGE', 'max')]),\n",
    "\n",
    "    (['CODE_GENDER', 'ORGANIZATION_TYPE'], [('AMT_ANNUITY', 'mean'),\n",
    "                                            ('AMT_CREDIT', 'mean'),\n",
    "                                            ('EXT_SOURCE_1', 'mean'),\n",
    "                                            ('EXT_SOURCE_2', 'mean'),\n",
    "                                            ('EXT_SOURCE_3', 'mean')]),\n",
    "    (['CODE_GENDER', 'REG_CITY_NOT_WORK_CITY'], [('AMT_ANNUITY', 'mean'),\n",
    "                                                ('DAYS_LAST_PHONE_CHANGE', 'mean'),\n",
    "                                                ('DAYS_REGISTRATION', 'mean'),\n",
    "                                                ('CNT_CHILDREN', 'mean')]),\n",
    "\n",
    "                                              \n",
    "                                                                                                                                             \n",
    "]\n",
    "groupby_aggregate_names = []\n",
    "for groupby_cols, specs in tqdm(agregaciones):\n",
    "    group_object = app_train.groupby(groupby_cols)\n",
    "    for select, agg in tqdm(specs):\n",
    "        groupby_aggregate_name = '{}_{}_{}'.format('_'.join(groupby_cols), agg, select)\n",
    "        app_train = app_train.merge(group_object[select]\n",
    "                              .agg(agg)\n",
    "                              .reset_index()\n",
    "                              .rename(index=str,\n",
    "                                      columns={select: groupby_aggregate_name})\n",
    "                              [groupby_cols + [groupby_aggregate_name]],\n",
    "                              on=groupby_cols,\n",
    "                              how='left')\n",
    "        groupby_aggregate_names.append(groupby_aggregate_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e041464ed78447c49d0d60fefa8d9632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1912cfeefa69459187df4dfbd83fd20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb8a1c75ce34c0c97b5a78f604b0e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342c270847d542cb980984c2eedbcfcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AGREGACIONES\n",
    "agregaciones = [\n",
    "    (['CODE_GENDER', 'NAME_EDUCATION_TYPE'], [('AMT_ANNUITY', 'max'),\n",
    "                                              ('AMT_CREDIT', 'max'),\n",
    "                                              ('EXT_SOURCE_1', 'mean'),\n",
    "                                              ('EXT_SOURCE_2', 'mean'),\n",
    "                                              ('EXT_SOURCE_3', 'mean'),\n",
    "                                              ('AGE_INT', 'mean'),\n",
    "                                              ('OWN_CAR_AGE', 'max')]),\n",
    "\n",
    "    (['CODE_GENDER', 'ORGANIZATION_TYPE'], [('AMT_ANNUITY', 'mean'),\n",
    "                                            ('AMT_CREDIT', 'mean'),\n",
    "                                            ('EXT_SOURCE_1', 'mean'),\n",
    "                                            ('EXT_SOURCE_2', 'mean'),\n",
    "                                            ('EXT_SOURCE_3', 'mean')]),\n",
    "    (['CODE_GENDER', 'REG_CITY_NOT_WORK_CITY'], [('AMT_ANNUITY', 'mean'),\n",
    "                                                ('DAYS_LAST_PHONE_CHANGE', 'mean'),\n",
    "                                                ('DAYS_REGISTRATION', 'mean'),\n",
    "                                                ('CNT_CHILDREN', 'mean')]),\n",
    "\n",
    "                                              \n",
    "                                                                                                                                             \n",
    "]\n",
    "groupby_aggregate_names = []\n",
    "for groupby_cols, specs in tqdm(agregaciones):\n",
    "    group_object = app_test_pruebav1.groupby(groupby_cols)\n",
    "    for select, agg in tqdm(specs):\n",
    "        groupby_aggregate_name = '{}_{}_{}'.format('_'.join(groupby_cols), agg, select)\n",
    "        app_test_pruebav1 = app_test_pruebav1.merge(group_object[select]\n",
    "                              .agg(agg)\n",
    "                              .reset_index()\n",
    "                              .rename(index=str,\n",
    "                                      columns={select: groupby_aggregate_name})\n",
    "                              [groupby_cols + [groupby_aggregate_name]],\n",
    "                              on=groupby_cols,\n",
    "                              how='left')\n",
    "        groupby_aggregate_names.append(groupby_aggregate_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48744, 1188)\n",
      "(307511, 1188)\n"
     ]
    }
   ],
   "source": [
    "print(app_test_pruebav1.shape)\n",
    "print(app_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48744 entries, 0 to 48743\n",
      "Columns: 976 entries, SK_ID_CURR to CODE_GENDER_REG_CITY_NOT_WORK_CITY_mean_CNT_CHILDREN\n",
      "dtypes: float64(913), int64(44), object(19)\n",
      "memory usage: 363.0+ MB\n",
      "None\n",
      "0        100001\n",
      "1        100005\n",
      "2        100013\n",
      "3        100028\n",
      "4        100038\n",
      "          ...  \n",
      "48739    456221\n",
      "48740    456222\n",
      "48741    456223\n",
      "48742    456224\n",
      "48743    456250\n",
      "Name: SK_ID_CURR, Length: 48744, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_nan_cols = [i for i in app_test_pruebav1 if app_test_pruebav1[i].isnull().all()]\n",
    "print(all_nan_cols)\n",
    "#app_test_pruebav1.drop(columns=all_nan_cols, inplace=True)\n",
    "print(app_test_pruebav1.info())\n",
    "print(app_test_pruebav1['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en app_train después de la imputación:\n",
      "0\n",
      "(307511, 1188)\n",
      "Valores nulos en app_test después de la imputación:\n",
      "146232\n",
      "(48744, 1188)\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento previo a la creación de los modelos\n",
    "# Imputación de valores nulos. Vamos a probar de momento a completar variables numéricos con la media\n",
    "# y las categóricas con la moda.\n",
    "# Como sabemos que DAYS_EMPLOYEED tiene un valor erroneo, vamos a reemplazarlo por NaN\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "app_train['DAYS_LAST_PHONE_CHANGE'].replace({0: np.nan}, inplace = True)\n",
    "app_train['NAME_FAMILY_STATUS'].replace('Unknown', np.nan, inplace=True)\n",
    "app_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "app_test_pruebav1['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "app_test_pruebav1['DAYS_LAST_PHONE_CHANGE'].replace({0: np.nan}, inplace = True)\n",
    "app_test_pruebav1['NAME_FAMILY_STATUS'].replace('Unknown', np.nan, inplace=True)\n",
    "app_test_pruebav1.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# Algunas variables categóricas tienen valores como XNA, vamos a reemplazarlos por NaN\n",
    "def reemplazar_xna_por_nan(app_train):\n",
    "    variables_categoricas = app_train.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in variables_categoricas:\n",
    "        app_train[col] = app_train[col].replace('XNA', np.nan)\n",
    "        #app_train[col] = app_train[col].replace('XAP', np.nan)\n",
    "    return app_train\n",
    "app_train_noxna = reemplazar_xna_por_nan(app_train)\n",
    "app_test_noxna = reemplazar_xna_por_nan(app_test_pruebav1)\n",
    "\n",
    "def imputar_valores_nulos(app_train):\n",
    "    variables_continuas = app_train.select_dtypes(include=[np.number]).columns \n",
    "    for col in variables_continuas:\n",
    "        app_train[col] = app_train[col].fillna(app_train[col].mean())\n",
    "    variables_categoricas = app_train.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in variables_categoricas:\n",
    "        app_train[col] = app_train[col].fillna(app_train[col].mode()[0])\n",
    "\n",
    "    return app_train\n",
    "\n",
    "app_train_nonan = imputar_valores_nulos(app_train_noxna)\n",
    "app_test_nonan = imputar_valores_nulos(app_test_noxna)\n",
    "\n",
    "#Comprobamos que no haya valores nulos\n",
    "#print(app_train['DAYS_BIRTH'].unique())\n",
    "#print(app_train['DAYS_BIRTH'].isnull().sum())\n",
    "#print(app_train['DAYS_BIRTH'].dtype)\n",
    "\n",
    "# Verificar si hay valores nulos en app_train después de la imputación\n",
    "print(\"Valores nulos en app_train después de la imputación:\")\n",
    "print(app_train_nonan.isnull().sum().sum())\n",
    "print(app_train_nonan.shape)\n",
    "print(\"Valores nulos en app_test después de la imputación:\")\n",
    "print(app_test_nonan.isnull().sum().sum()) \n",
    "print(app_test_nonan.shape)\n",
    "#print(app_test_nonan['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 1188 entries, TARGET to CODE_GENDER_REG_CITY_NOT_WORK_CITY_mean_CNT_CHILDREN\n",
      "dtypes: float64(1125), int64(44), object(19)\n",
      "memory usage: 2.7+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48744 entries, 0 to 48743\n",
      "Columns: 1188 entries, SK_ID_CURR to CODE_GENDER_REG_CITY_NOT_WORK_CITY_mean_CNT_CHILDREN\n",
      "dtypes: float64(1125), int64(44), object(19)\n",
      "memory usage: 441.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(app_train_nonan.info())\n",
    "print(app_test_nonan.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (307511, 1322) Test shape: (48744, 1322)\n",
      "Valores nulos en app_train después de la imputación: 0\n",
      "Valores nulos en app_test después de la imputación: 146232\n",
      "0        100001\n",
      "1        100005\n",
      "2        100013\n",
      "3        100028\n",
      "4        100038\n",
      "          ...  \n",
      "48739    456221\n",
      "48740    456222\n",
      "48741    456223\n",
      "48742    456224\n",
      "48743    456250\n",
      "Name: SK_ID_CURR, Length: 48744, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Diccionario para almacenar los LabelEncoders de variables binarias\n",
    "label_encoders_binarias = {}\n",
    "\n",
    "def label_encoding_binarias_fit(df):\n",
    "    variables_categoricas = df.select_dtypes(include=['object','category']).columns\n",
    "    variables_categoricas_binarias = [col for col in variables_categoricas if df[col].nunique() == 2]\n",
    "    for col in variables_categoricas_binarias:\n",
    "        enc = LabelEncoder()\n",
    "        enc.fit(df[col])\n",
    "        label_encoders_binarias[col] = enc\n",
    "\n",
    "def label_encoding_binarias_transform(df):\n",
    "    df = df.copy()\n",
    "    for col in label_encoders_binarias:\n",
    "        df[col] = label_encoders_binarias[col].transform(df[col])\n",
    "    return df\n",
    "\n",
    "# Suponiendo que app_train_noxna y app_test_noxna ya tienen los tipos de datos necesarios\n",
    "app_train_noxna = app_train_noxna.select_dtypes(include=[np.number, 'object', 'category'])\n",
    "app_test_noxna = app_test_noxna.select_dtypes(include=[np.number, 'object', 'category'])\n",
    "\n",
    "# Aplicamos el label encoding para variables binarias\n",
    "label_encoding_binarias_fit(app_train_noxna)\n",
    "app_train_nonan_le = label_encoding_binarias_transform(app_train_noxna)\n",
    "app_test_nonan_le = label_encoding_binarias_transform(app_test_noxna)\n",
    "\n",
    "# Identificar las columnas categóricas no binarias (más de 2 categorías) en el conjunto de train\n",
    "cols_no_binarias = [col for col in app_train_nonan_le.select_dtypes(include=['object', 'category']).columns \n",
    "                    if app_train_nonan_le[col].nunique() > 2]\n",
    "\n",
    "# Inicializamos y ajustamos el OneHotEncoder en el conjunto de train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "ohe.fit(app_train_nonan_le[cols_no_binarias])\n",
    "\n",
    "# Transformamos ambos conjuntos (train y test)\n",
    "train_ohe = ohe.transform(app_train_nonan_le[cols_no_binarias])\n",
    "test_ohe = ohe.transform(app_test_nonan_le[cols_no_binarias])\n",
    "\n",
    "# Convertir los arrays a DataFrames, asignando nombres a las columnas generadas\n",
    "ohe_columns = ohe.get_feature_names_out(cols_no_binarias)\n",
    "train_ohe_df = pd.DataFrame(train_ohe, columns=ohe_columns, index=app_train_nonan_le.index)\n",
    "test_ohe_df = pd.DataFrame(test_ohe, columns=ohe_columns, index=app_test_nonan_le.index)\n",
    "\n",
    "# Eliminamos las columnas categóricas originales no binarias y concatenamos las variables one-hot\n",
    "app_train_final = pd.concat([app_train_nonan_le.drop(columns=cols_no_binarias), train_ohe_df], axis=1)\n",
    "app_test_final = pd.concat([app_test_nonan_le.drop(columns=cols_no_binarias), test_ohe_df], axis=1)\n",
    "\n",
    "# Mostramos las formas y comprobamos la existencia de valores nulos\n",
    "print(\"Train shape:\", app_train_final.shape, \"Test shape:\", app_test_final.shape)\n",
    "print(\"Valores nulos en app_train después de la imputación:\", app_train_final.isnull().sum().sum())\n",
    "print(\"Valores nulos en app_test después de la imputación:\", app_test_final.isnull().sum().sum())\n",
    "\n",
    "# Imprime la columna SK_ID_CURR del test para verificar que se conserva\n",
    "print(app_test_final['SK_ID_CURR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en app_train después de la normalización:\n",
      "0\n",
      "Información del DataFrame train normalizado:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 1322 entries, TARGET to LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Sold\n",
      "dtypes: float64(1280), int64(42)\n",
      "memory usage: 3.0 GB\n",
      "None\n",
      "Máximos valores en train:\n",
      "TARGET                                                  1.0\n",
      "NAME_CONTRACT_TYPE                                      1.0\n",
      "CODE_GENDER                                             1.0\n",
      "FLAG_OWN_CAR                                            1.0\n",
      "FLAG_OWN_REALTY                                         1.0\n",
      "                                                       ... \n",
      "LATEST_CREDIT_TYPE_CAT_(BUREAU)_Unknown type of loan    1.0\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Active                1.0\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Bad debt              1.0\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Closed                1.0\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Sold                  1.0\n",
      "Length: 1322, dtype: float64\n",
      "Valores nulos en app_test después de la normalización:\n",
      "146232\n",
      "Información del DataFrame test normalizado:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48744 entries, 0 to 48743\n",
      "Columns: 1322 entries, SK_ID_CURR to LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Sold\n",
      "dtypes: float64(1281), int64(41)\n",
      "memory usage: 491.6 MB\n",
      "None\n",
      "Máximos valores en test:\n",
      "SK_ID_CURR                                              1.0\n",
      "NAME_CONTRACT_TYPE                                      1.0\n",
      "CODE_GENDER                                             1.0\n",
      "FLAG_OWN_CAR                                            1.0\n",
      "FLAG_OWN_REALTY                                         1.0\n",
      "                                                       ... \n",
      "LATEST_CREDIT_TYPE_CAT_(BUREAU)_Unknown type of loan    1.0\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Active                1.0\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Bad debt              1.0\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Closed                1.0\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Sold                  1.0\n",
      "Length: 1322, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Identificar las variables continuas que necesitan normalización en train\n",
    "variables_continuas = app_train_final.select_dtypes(include=['int64', 'float64']).columns\n",
    "variables_normalizadas = [col for col in variables_continuas if\n",
    "                          app_train_final[col].min() >= 0 and app_train_final[col].max() <= 1]\n",
    "variables_NO_normalizadas = [col for col in variables_continuas if col not in variables_normalizadas]\n",
    "\n",
    "# Identificar las variables continuas que necesitan normalización en test\n",
    "variables_continuas_test = app_test_final.select_dtypes(include=['int64', 'float64']).columns\n",
    "variables_normalizadas_test = [col for col in variables_continuas_test if\n",
    "                               app_test_final[col].min() >= 0 and app_test_final[col].max() <= 1]\n",
    "variables_NO_normalizadas_test = [col for col in variables_continuas_test if col not in variables_normalizadas_test]\n",
    "\n",
    "# Diccionario para almacenar los escaladores ajustados\n",
    "scalers = {}\n",
    "\n",
    "# Función para ajustar el escalador a las variables no normalizadas\n",
    "def normalizacion_fit(data, cols, scaler_type='minmax'):\n",
    "    for col in cols:\n",
    "        if scaler_type == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scaler_type == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "        else:\n",
    "            raise ValueError(\"Tipo de escalador no reconocido. Usa 'minmax' o 'robust'.\")\n",
    "        scaler.fit(data[[col]])\n",
    "        scalers[col] = scaler\n",
    "\n",
    "# Función para transformar las variables utilizando los escaladores ajustados\n",
    "def normalizacion_transform(data, cols):\n",
    "    data = data.copy()  # Evitar modificar el original\n",
    "    for col in cols:\n",
    "        if col in scalers:\n",
    "            data[col] = scalers[col].transform(data[[col]])\n",
    "    return data\n",
    "\n",
    "# Ajustar los escaladores a las variables no normalizadas en el conjunto de entrenamiento\n",
    "normalizacion_fit(app_train_final, variables_NO_normalizadas, scaler_type='minmax')\n",
    "# Nota: Por lo general se ajustan los escaladores en train y luego se aplican a test,\n",
    "# pero si prefieres ajustar de forma independiente en test, lo haces también:\n",
    "normalizacion_fit(app_test_final, variables_NO_normalizadas_test, scaler_type='minmax')\n",
    "\n",
    "# Transformar el conjunto de entrenamiento y el de test\n",
    "app_train_final_norm = normalizacion_transform(app_train_final, variables_NO_normalizadas)\n",
    "app_test_final_norm = normalizacion_transform(app_test_final, variables_NO_normalizadas_test)\n",
    "\n",
    "# Verificar los valores nulos y la información del DataFrame transformado\n",
    "print(\"Valores nulos en app_train después de la normalización:\")\n",
    "print(app_train_final_norm.isnull().sum().sum())\n",
    "print(\"Información del DataFrame train normalizado:\")\n",
    "print(app_train_final_norm.info())\n",
    "print(\"Máximos valores en train:\")\n",
    "print(app_train_final_norm.max())\n",
    "\n",
    "print(\"Valores nulos en app_test después de la normalización:\")\n",
    "print(app_test_final_norm.isnull().sum().sum())\n",
    "print(\"Información del DataFrame test normalizado:\")\n",
    "print(app_test_final_norm.info())\n",
    "print(\"Máximos valores en test:\")\n",
    "print(app_test_final_norm.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48744, 1322)\n",
      "(307511, 1322)\n"
     ]
    }
   ],
   "source": [
    "#print(app_train_nonan_le_oh_norm.shape)\n",
    "print(app_test_final_norm.shape)\n",
    "print(app_train_final_norm.shape)\n",
    "#print(app_test_nonan_le_oh_norm['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos el csv tras todo el preprocesamiento\n",
    "#TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/bureau_agg_final.csv\n",
    "#bureau_agg.to_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/bureau_agg_final.csv', index=False)\n",
    "app_train_final_norm.to_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/application_train_preprocesado_definitivo_v7.csv')\n",
    "app_test_final_norm.to_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/app_test_pruebav1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg-py3.12",
   "language": "python",
   "name": "tfg-py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
