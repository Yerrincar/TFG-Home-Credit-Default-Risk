{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n",
      "Directorio actual: /home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS\n",
      "(307511, 122) (305811, 404) (305811, 23) (338857, 361)\n"
     ]
    }
   ],
   "source": [
    "#Celda para librerías\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(np.__version__)\n",
    "from ydata_profiling import ProfileReport\n",
    "import os\n",
    "print(\"Directorio actual:\", os.getcwd())\n",
    "\n",
    "# Have all columns appear when dataframes are displayed.\n",
    "pd.set_option('display.max_columns', None) \n",
    "# Have 100 rows appear when a dataframe is displayed\n",
    "pd.set_option('display.max_rows', 500)\n",
    "# Display dimensions whenever a dataframe is printed out.\n",
    "pd.set_option('display.show_dimensions', True)\n",
    "\n",
    "#Importando los datos\n",
    "\n",
    "app_train = pd.read_csv(r'/home/yeray/home-credit-default-risk/application_train.csv')\n",
    "bureau_final = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/bureau_agg_final.csv')\n",
    "bureau_balance__agg_def_v1 = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/bureau_balance_agg_def.csv')\n",
    "previous_application_agg = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/prev_app.csv')\n",
    "print(app_train.shape\n",
    "      , bureau_final.shape\n",
    "      , bureau_balance__agg_def_v1.shape\n",
    "      , previous_application_agg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar los tipos de datos\n",
    "print(app_train['SK_ID_CURR'].dtype)\n",
    "print(bureau_final['SK_ID_CURR'].dtype)\n",
    "print(bureau_balance__agg_def_v1['SK_ID_CURR'].dtype)\n",
    "print(previous_application_agg['SK_ID_CURR'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 908 entries, TARGET to HAS_CHILDREN\n",
      "dtypes: float64(848), int64(41), object(19)\n",
      "memory usage: 2.1+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Uniendo los datos\n",
    "app_train = app_train.merge(bureau_final, on='SK_ID_CURR', how='left')\n",
    "app_train = app_train.merge(bureau_balance__agg_def_v1, on='SK_ID_CURR', how='left')\n",
    "app_train = app_train.merge(previous_application_agg, on='SK_ID_CURR', how='left')\n",
    "\n",
    "app_train.drop(columns=['SK_ID_CURR'], inplace=True)\n",
    "#Debido a un fallo que detecta que todas los valores de la columna DAYS_BIRTH \n",
    "# son nan cuando no es así, vamos a sustituir la columna por una nueva llamada AGE_INT\n",
    "app_train['AGE_INT'] = app_train['DAYS_BIRTH']/-365\n",
    "app_train['HAS_CHILDREN'] = np.where(app_train['CNT_CHILDREN'] > 0, 1, 0)\n",
    "#variables_categoricas = app_train.select_dtypes(include=['object', 'category']).columns\n",
    "#app_train[variables_categoricas] = app_train[variables_categoricas].astype('category')\n",
    "#categoricas = variables_categoricas.tolist()\n",
    "info = app_train.info()\n",
    "print(info)\n",
    "#describe = app_train.describe()\n",
    "#print(describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TARGET', 'CNT_CHILDREN', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
       "       'DAYS_ID_PUBLISH', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE',\n",
       "       'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'REGION_RATING_CLIENT',\n",
       "       'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START',\n",
       "       'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n",
       "       'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',\n",
       "       'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_2',\n",
       "       'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5',\n",
       "       'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8',\n",
       "       'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11',\n",
       "       'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14',\n",
       "       'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17',\n",
       "       'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20',\n",
       "       'FLAG_DOCUMENT_21', 'HAS_CHILDREN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "app_train.select_dtypes(include=['int64']).columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "\n",
    "\n",
    "#Vamos a convertir la variable CNT_CHILDREN en una variable categórica que indique 1 si tiene hijos y 0 si no.\n",
    "\n",
    "#Vamos a crear la variable DAYS_EMPLOYED en una variable categórica que indique 1 si tiene empleo y 0 si no.\n",
    "app_train['HAS_EMPLOYMENT'] = app_train['DAYS_EMPLOYED'].map(lambda app_train: 1 if app_train < 0 else 0)\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "\n",
    "#Voy a crear RATIOS para algunas de las variables más importantes (en mi opinión y según lo investigado) \n",
    "# y que además tienen valores atípicos.\n",
    "app_train['CREDIT_AMT_INCOME_RATIO'] = app_train['AMT_CREDIT']/app_train['AMT_INCOME_TOTAL']\n",
    "app_train['CREDIT_AMT_INCOME_PORCENTAJE'] = app_train['AMT_INCOME_TOTAL']/app_train['AMT_CREDIT']\n",
    "\n",
    "app_train['ANNUITY_AMT_INCOME_RATIO'] = app_train['AMT_INCOME_TOTAL']/app_train['AMT_ANNUITY']\n",
    "app_train['ANNUITY_INCOME_PORCENTAJE'] = app_train['AMT_ANNUITY']/app_train['AMT_INCOME_TOTAL']\n",
    "\n",
    "app_train['GOODS_INCOME_RATIO'] = app_train['AMT_GOODS_PRICE']/app_train['AMT_INCOME_TOTAL']\n",
    "\n",
    "app_train['CREDIT_ANNUITY_RATIO'] = app_train['AMT_CREDIT']/app_train['AMT_ANNUITY']\n",
    "app_train['ANNUITY_CREDIT_PORCETAJE'] = app_train['AMT_ANNUITY']/app_train['AMT_CREDIT']\n",
    "app_train['CREDIT_GOODS_PRICE_RATIO'] = app_train['AMT_CREDIT']/app_train['AMT_GOODS_PRICE']\n",
    "\n",
    "app_train['ANNUITY_TO_DAYS_EMPLOYED_RATIO'] = app_train['AMT_ANNUITY']/app_train['DAYS_EMPLOYED']\n",
    "app_train['ANNUITY_TO_CHILDREN_RATIO'] = app_train['AMT_ANNUITY']/app_train['CNT_CHILDREN']\n",
    "\n",
    "app_train['INCOME_PER_CHILD'] = app_train['AMT_INCOME_TOTAL']/app_train['CNT_CHILDREN']\n",
    "app_train['CREDIT_PER_CHILD'] = app_train['AMT_CREDIT']/app_train['CNT_CHILDREN']\n",
    "\n",
    "app_train['AMT_INCOME_FAMILY_MEMBERS_RATIO'] = app_train['AMT_INCOME_TOTAL']/app_train['CNT_FAM_MEMBERS']\n",
    "app_train['CHILDREN_RATIO'] = app_train['CNT_CHILDREN']/app_train['CNT_FAM_MEMBERS']\n",
    "app_train['ADULTS_MEMBERS_DIFF'] = app_train['CNT_FAM_MEMBERS'] - app_train['CNT_CHILDREN']\n",
    "\n",
    "app_train['INCOME_PER_ADULT'] = app_train['AMT_INCOME_TOTAL']/app_train['ADULTS_MEMBERS_DIFF']\n",
    "app_train['CREDIT_PER_MEMBER'] = app_train['AMT_CREDIT']/app_train['CNT_FAM_MEMBERS']\n",
    "app_train['CREDIT_PER_ADULT'] = app_train['AMT_CREDIT']/app_train['ADULTS_MEMBERS_DIFF']\n",
    "app_train['ANNUITY_PER_ADULT'] = app_train['AMT_ANNUITY']/app_train['ADULTS_MEMBERS_DIFF']\n",
    "\n",
    "\n",
    "#app_train['OWN_CAR_AGE_RATIO'] = app_train['OWN_CAR_AGE']/app_train['AGE_INT']\n",
    "app_train['NEW_CAR_BIRTH_RATIO'] = app_train['OWN_CAR_AGE']/app_train['DAYS_BIRTH']\n",
    "app_train['NEW_CAR_EMPLOYMENT_RATIO'] = app_train['OWN_CAR_AGE']/app_train['DAYS_EMPLOYED']\n",
    "\n",
    "\n",
    "app_train['EMPLOYMENT_AGE_RATIO'] = app_train['DAYS_EMPLOYED']/-app_train['AGE_INT']\n",
    "#app_train['EMPLOYMENT_BIRTH_RATIO'] = app_train['DAYS_EMPLOYED']/app_train['DAYS_BIRTH']\n",
    "app_train['EMPLOYMENT_PHONE_CHANGE_RATIO'] = app_train['DAYS_LAST_PHONE_CHANGE']/app_train['DAYS_EMPLOYED']\n",
    "\n",
    "app_train['NEW_PHONE_CHANGE_BIRTH_RATIO'] = app_train['DAYS_LAST_PHONE_CHANGE']/app_train['DAYS_BIRTH']\n",
    "app_train['NEW_PHONE_CHANGE_EMPLOYMENT_RATIO'] = app_train['DAYS_LAST_PHONE_CHANGE']/app_train['DAYS_EMPLOYED']\n",
    "app_train['DAYS_ID_PUBLISH_BIRTH_RAIO'] = app_train['DAYS_ID_PUBLISH']/app_train['DAYS_BIRTH']\n",
    "\n",
    "app_train['REGISTRATION_TO_NEW_PHONE_CHANGE_RATIO'] = app_train['DAYS_LAST_PHONE_CHANGE']/app_train['DAYS_REGISTRATION']\n",
    "#app_train['REGISTRATION_TO_ID_PUBLISH_RATIO'] = app_train['DAYS_ID_PUBLISH'] - app_train['DAYS_REGISTRATION']\n",
    "#app_train['REGISTRATION_TO_BIRTH_RATIO'] = app_train['DAYS_BIRTH'] - app_train['DAYS_REGISTRATION']\n",
    "\n",
    "#EXT_SOURCE son variables representan fuentes externas de información sobre el cliente, y suelen estar relacionadas con puntuaciones de riesgo crediticio generadas por \n",
    "# instituciones externas al prestamista, como burós de crédito u otras entidades que evalúan el perfil financiero de los clientes.\n",
    "#Vamos a crear variables relacionadas con EXT_SOURCE.\n",
    "\n",
    "app_train['EXT_SOURCE_SUM'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis=1)\n",
    "app_train['EXT_SOURCE_MEAN'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "app_train['EXT_SOURCE_MEDIAN'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].median(axis=1)\n",
    "app_train['EXT_SOURCE_MAX'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].max(axis=1)\n",
    "app_train['EXT_SOURCE_MIN'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].min(axis=1)\n",
    "\n",
    "app_train['EXT_SOURCE_WEIGHTED_SUM'] = app_train['EXT_SOURCE_1']*3 + app_train['EXT_SOURCE_2']*1 + app_train['EXT_SOURCE_3']*5\n",
    "app_train['EXT_SOURCE_WEIGHTED_MEAN'] = (app_train['EXT_SOURCE_1']*3 + app_train['EXT_SOURCE_2']*1 + app_train['EXT_SOURCE_3']*5)/3\n",
    "app_train['EXT_SOURCE_PROD'] = app_train['EXT_SOURCE_1']*app_train['EXT_SOURCE_2']*app_train['EXT_SOURCE_3']\n",
    "\n",
    "app_train['RATIO_EXT_SOURCE_3_TO_REGION_POPULATION_RELATIVE'] = app_train['EXT_SOURCE_3'] / app_train['REGION_POPULATION_RELATIVE']\n",
    "\n",
    "\"\"\"\n",
    "app_train['AGE_CREDIT_RATIO'] = app_train['AGE_INT']/app_train['AMT_CREDIT']\n",
    "app_train['AGE_ANNUITY_RATIO'] = app_train['AGE_INT']/app_train['AMT_ANNUITY']\n",
    "app_train['AGE_GOODS_PRICE_RATIO'] = app_train['AGE_INT']/app_train['AMT_GOODS_PRICE']\n",
    "app_train['AGE_INCOME_RATIO'] = app_train['AGE_INT']/app_train['AMT_INCOME_TOTAL']\n",
    "\"\"\"\n",
    "app_train['AGE_CREDIT_RATIO'] = app_train['AMT_CREDIT']/app_train['DAYS_BIRTH']\n",
    "app_train['AGE_ANNUITY_RATIO'] = app_train['AMT_ANNUITY']/app_train['DAYS_BIRTH']\n",
    "app_train['AGE_GOODS_PRICE_RATIO'] = app_train['AMT_GOODS_PRICE']/app_train['DAYS_BIRTH']\n",
    "app_train['AGE_INCOME_RATIO'] = app_train['AMT_INCOME_TOTAL']/app_train['DAYS_BIRTH']\n",
    "\n",
    "\n",
    "\n",
    "#Variables a partir de sumas y diferencias\n",
    "app_train['AMT_INCOME_TOTAL_ANNUITY_SUM'] = app_train['AMT_INCOME_TOTAL'] + app_train['AMT_ANNUITY']\n",
    "app_train['AMT_GOODS_TO_INCOME_ANUITY_SUM_RATIO'] = app_train['AMT_GOODS_PRICE']/(app_train['AMT_INCOME_TOTAL_ANNUITY_SUM'] )\n",
    "app_train['CREDIT_BUREAU_TOTAL'] = app_train[['AMT_REQ_CREDIT_BUREAU_DAY', \n",
    "                                             'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "                                             'AMT_REQ_CREDIT_BUREAU_MON',\n",
    "                                             'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "                                             'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "                                             'AMT_REQ_CREDIT_BUREAU_YEAR']].sum(axis=1)\n",
    "\n",
    "app_train['CREDIT_GOODS_DIFF'] = app_train['AMT_GOODS_PRICE'] - app_train['AMT_CREDIT']\n",
    "app_train['GOODS_ANNUITY_DIFF'] = app_train['AMT_ANNUITY'] - app_train['AMT_GOODS_PRICE']\n",
    "app_train['AMT_INCOME_TOTAL_ANNUITY_DIFF'] = app_train['AMT_INCOME_TOTAL'] - app_train['AMT_ANNUITY']\n",
    "\n",
    "#app_train['SOCIAL_OBSERVATION_TOTAL'] = app_train['OBS_30_CNT_SOCIAL_CIRCLE'] + app_train['OBS_60_CNT_SOCIAL_CIRCLE']\n",
    "#app_train['SOCIAL_DEF_TOTAL'] = app_train['DEF_30_CNT_SOCIAL_CIRCLE'] + app_train['DEF_60_CNT_SOCIAL_CIRCLE']\n",
    "\n",
    "app_train['DIFF_OBS_30_60'] = app_train['OBS_30_CNT_SOCIAL_CIRCLE'] - app_train['OBS_60_CNT_SOCIAL_CIRCLE']\n",
    "app_train['DIFF_DEF_30_60'] = app_train['DEF_30_CNT_SOCIAL_CIRCLE'] - app_train['DEF_60_CNT_SOCIAL_CIRCLE'] \n",
    "\n",
    "app_train['LONG_EMPLOYMENT'] = np.where(app_train['DAYS_EMPLOYED'] < -2000, 1, 0)\n",
    "app_train['RETIRED'] = np.where(app_train['DAYS_BIRTH'] < -14000, 1, 0)\n",
    "\n",
    "#OTRAS\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    307511.000000\n",
      "mean          2.509507\n",
      "std           0.874544\n",
      "min           1.000000\n",
      "25%           2.000000\n",
      "50%           2.000000\n",
      "75%           3.000000\n",
      "max           5.000000\n",
      "Name: EDUCATION_LEVEL, Length: 8, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nincome_type_mapping = {\\n    'Unemployed': 0,\\n    'Student': 1,\\n    'Pensioner': 2,\\n    'Maternity leave': 3,\\n    'Working': 4,\\n    'State servant': 5,\\n    'Commercial associate': 6,\\n    'Businessman': 7,    \\n}\\napp_train['INCOME_TYPE'] = app_train['NAME_INCOME_TYPE'].map(income_type_mapping)\\n\\nfamily_mapping = {\\n    'Single / not married': 0,\\n    'Separated': 1,\\n    'Widow': 2,\\n    'Married': 3\\n}\\n\\nhousing_mapping = {\\n    'With parents': 0,\\n    'Municipal apartment': 1,\\n    'Rented apartment': 2,\\n    'House / apartment': 3\\n}\\n\\n\\n\\napp_train['FAMILY_STATUS'] = app_train['NAME_FAMILY_STATUS'].map(family_mapping)\\napp_train['HOUSING_TYPE'] = app_train['NAME_HOUSING_TYPE'].map(housing_mapping)\\n\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_mapping = {\n",
    "    'No formal education': 0,\n",
    "    'Lower secondary': 1,\n",
    "    'Secondary / secondary special': 2,\n",
    "    'Incomplete higher': 3,\n",
    "    'Higher education': 4,\n",
    "    'Academic degree': 5\n",
    "}\n",
    "\n",
    "app_train['EDUCATION_LEVEL'] = app_train['NAME_EDUCATION_TYPE'].map(education_mapping)\n",
    "print(app_train['EDUCATION_LEVEL'].describe())\n",
    "\"\"\"\n",
    "income_type_mapping = {\n",
    "    'Unemployed': 0,\n",
    "    'Student': 1,\n",
    "    'Pensioner': 2,\n",
    "    'Maternity leave': 3,\n",
    "    'Working': 4,\n",
    "    'State servant': 5,\n",
    "    'Commercial associate': 6,\n",
    "    'Businessman': 7,    \n",
    "}\n",
    "app_train['INCOME_TYPE'] = app_train['NAME_INCOME_TYPE'].map(income_type_mapping)\n",
    "\n",
    "family_mapping = {\n",
    "    'Single / not married': 0,\n",
    "    'Separated': 1,\n",
    "    'Widow': 2,\n",
    "    'Married': 3\n",
    "}\n",
    "\n",
    "housing_mapping = {\n",
    "    'With parents': 0,\n",
    "    'Municipal apartment': 1,\n",
    "    'Rented apartment': 2,\n",
    "    'House / apartment': 3\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "app_train['FAMILY_STATUS'] = app_train['NAME_FAMILY_STATUS'].map(family_mapping)\n",
    "app_train['HOUSING_TYPE'] = app_train['NAME_HOUSING_TYPE'].map(housing_mapping)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b3709a852a40af8ac502ca4e8d11f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156f3c8a67424fb7b6559256eb37c1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3821f44321514261a6f905b9601996e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8c3870f2ec41c4a7ce6a6569688911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AGREGACIONES\n",
    "agregaciones = [\n",
    "    (['CODE_GENDER', 'NAME_EDUCATION_TYPE'], [('AMT_ANNUITY', 'max'),\n",
    "                                              ('AMT_CREDIT', 'max'),\n",
    "                                              ('EXT_SOURCE_1', 'mean'),\n",
    "                                              ('EXT_SOURCE_2', 'mean'),\n",
    "                                              ('EXT_SOURCE_3', 'mean'),\n",
    "                                              ('AGE_INT', 'mean'),\n",
    "                                              ('OWN_CAR_AGE', 'max')]),\n",
    "\n",
    "    (['CODE_GENDER', 'ORGANIZATION_TYPE'], [('AMT_ANNUITY', 'mean'),\n",
    "                                            ('AMT_CREDIT', 'mean'),\n",
    "                                            ('EXT_SOURCE_1', 'mean'),\n",
    "                                            ('EXT_SOURCE_2', 'mean'),\n",
    "                                            ('EXT_SOURCE_3', 'mean')]),\n",
    "    (['CODE_GENDER', 'REG_CITY_NOT_WORK_CITY'], [('AMT_ANNUITY', 'mean'),\n",
    "                                                ('DAYS_LAST_PHONE_CHANGE', 'mean'),\n",
    "                                                ('DAYS_REGISTRATION', 'mean'),\n",
    "                                                ('CNT_CHILDREN', 'mean')]),\n",
    "\n",
    "                                              \n",
    "                                                                                                                                             \n",
    "]\n",
    "groupby_aggregate_names = []\n",
    "for groupby_cols, specs in tqdm(agregaciones):\n",
    "    group_object = app_train.groupby(groupby_cols)\n",
    "    for select, agg in tqdm(specs):\n",
    "        groupby_aggregate_name = '{}_{}_{}'.format('_'.join(groupby_cols), agg, select)\n",
    "        app_train = app_train.merge(group_object[select]\n",
    "                              .agg(agg)\n",
    "                              .reset_index()\n",
    "                              .rename(index=str,\n",
    "                                      columns={select: groupby_aggregate_name})\n",
    "                              [groupby_cols + [groupby_aggregate_name]],\n",
    "                              on=groupby_cols,\n",
    "                              how='left')\n",
    "        groupby_aggregate_names.append(groupby_aggregate_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en app_train después de la imputación:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento previo a la creación de los modelos\n",
    "# Imputación de valores nulos. Vamos a probar de momento a completar variables numéricos con la media\n",
    "# y las categóricas con la moda.\n",
    "# Como sabemos que DAYS_EMPLOYEED tiene un valor erroneo, vamos a reemplazarlo por NaN\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "app_train['DAYS_LAST_PHONE_CHANGE'].replace({0: np.nan}, inplace = True)\n",
    "app_train['NAME_FAMILY_STATUS'].replace('Unknown', np.nan, inplace=True)\n",
    "# Reemplazar valores infinitos por NaN\n",
    "app_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# Algunas variables categóricas tienen valores como XNA, vamos a reemplazarlos por NaN\n",
    "def reemplazar_xna_por_nan(app_train):\n",
    "    variables_categoricas = app_train.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in variables_categoricas:\n",
    "        app_train[col] = app_train[col].replace('XNA', np.nan)\n",
    "        #app_train[col] = app_train[col].replace('XAP', np.nan)\n",
    "    return app_train\n",
    "app_train_noxna = reemplazar_xna_por_nan(app_train)\n",
    "\n",
    "app_train = reemplazar_xna_por_nan(app_train)\n",
    "def imputar_valores_nulos(app_train):\n",
    "    variables_continuas = app_train.select_dtypes(include=[np.number]).columns \n",
    "    for col in variables_continuas:\n",
    "        app_train[col] = app_train[col].fillna(app_train[col].mean())\n",
    "    variables_categoricas = app_train.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in variables_categoricas:\n",
    "        app_train[col] = app_train[col].fillna(app_train[col].mode()[0])\n",
    "\n",
    "    return app_train\n",
    "\n",
    "app_train_nonan = imputar_valores_nulos(app_train_noxna)\n",
    "#Comprobamos que no haya valores nulos\n",
    "#print(app_train['DAYS_BIRTH'].unique())\n",
    "#print(app_train['DAYS_BIRTH'].isnull().sum())\n",
    "#print(app_train['DAYS_BIRTH'].dtype)\n",
    "\n",
    "# Verificar si hay valores nulos en app_train después de la imputación\n",
    "print(\"Valores nulos en app_train después de la imputación:\")\n",
    "print(app_train_nonan.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en app_train después de la imputación:\n",
      "0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 1110 entries, TARGET to LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Sold\n",
      "dtypes: bool(148), float64(913), int64(49)\n",
      "memory usage: 2.2 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Selección de variables categóricas\n",
    "variables_categoricas = app_train.select_dtypes(include=['object', 'category']).columns\n",
    "variables_categoricas_binarias = [col for col in variables_categoricas if app_train[col].nunique() == 2]\n",
    "variables_categoricas_no_binarias = [col for col in variables_categoricas if app_train[col].nunique() > 2]\n",
    "\n",
    "# Diccionario para almacenar los LabelEncoders\n",
    "label_encoders_binarias = {}\n",
    "\n",
    "# Función para ajustar el LabelEncoder a las variables binarias\n",
    "def label_encoding_binarias_fit(app_train):\n",
    "    for col in variables_categoricas_binarias:\n",
    "        Encoder = LabelEncoder()\n",
    "        Encoder.fit(app_train[col])\n",
    "        label_encoders_binarias[col] = Encoder\n",
    "\n",
    "# Función para transformar las variables binarias utilizando los LabelEncoders ajustados\n",
    "def label_encoding_binarias_transform(data):\n",
    "    data = data.copy()  # Evitar modificar el original\n",
    "    for col in variables_categoricas_binarias:\n",
    "        if col in label_encoders_binarias:\n",
    "            data[col] = label_encoders_binarias[col].transform(data[col])\n",
    "    return data\n",
    "\n",
    "# Función para aplicar One-Hot Encoding a las variables no binarias\n",
    "def one_hot_encoding_no_binarias(data):\n",
    "    data = data.copy()  # Evitar modificar el original\n",
    "    data = pd.get_dummies(data, columns=variables_categoricas_no_binarias)\n",
    "    return data\n",
    "\n",
    "# Ajustar los LabelEncoders al conjunto de entrenamiento\n",
    "label_encoding_binarias_fit(app_train)\n",
    "\n",
    "# Transformar el conjunto de entrenamiento\n",
    "app_train_nonan_le = label_encoding_binarias_transform(app_train)\n",
    "\n",
    "# Aplicar One-Hot Encoding al conjunto de entrenamiento\n",
    "app_train_nonan_le_oh = one_hot_encoding_no_binarias(app_train_nonan_le)\n",
    "\n",
    "print(\"Valores nulos en app_train después de la imputación:\")\n",
    "print(app_train_nonan_le_oh.isnull().sum().sum())\n",
    "print(app_train_nonan_le_oh.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en app_train después de la imputación:\n",
      "0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 1110 entries, TARGET to LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Sold\n",
      "dtypes: bool(148), float64(920), int64(42)\n",
      "memory usage: 2.2 GB\n",
      "None\n",
      "TARGET                                                     1\n",
      "NAME_CONTRACT_TYPE                                         1\n",
      "CODE_GENDER                                                1\n",
      "FLAG_OWN_CAR                                               1\n",
      "FLAG_OWN_REALTY                                            1\n",
      "                                                        ... \n",
      "LATEST_CREDIT_TYPE_CAT_(BUREAU)_Unknown type of loan    True\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Active                True\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Bad debt              True\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Closed                True\n",
      "LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Sold                  True\n",
      "Length: 1110, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Identificar las variables continuas que necesitan normalización\n",
    "variables_continuas = app_train_nonan_le_oh.select_dtypes(include=['int64', 'float64']).columns\n",
    "variables_normalizadas = [col for col in variables_continuas if\n",
    "                          app_train_nonan_le_oh[col].min() >= 0 and app_train_nonan_le_oh[col].max() <= 1]\n",
    "variables_NO_normalizadas = [col for col in variables_continuas if col not in variables_normalizadas]\n",
    "\n",
    "# Diccionario para almacenar los escaladores ajustados\n",
    "scalers = {}\n",
    "\n",
    "# Función para ajustar el escalador a las variables no normalizadas\n",
    "def normalizacion_fit(data, cols, scaler_type='minmax'):\n",
    "    for col in cols:\n",
    "        if scaler_type == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scaler_type == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "        else:\n",
    "            raise ValueError(\"Tipo de escalador no reconocido. Usa 'minmax' o 'robust'.\")\n",
    "        scaler.fit(data[[col]])\n",
    "        scalers[col] = scaler\n",
    "\n",
    "# Función para transformar las variables utilizando los escaladores ajustados\n",
    "def normalizacion_transform(data, cols):\n",
    "    data = data.copy()  # Evitar modificar el original\n",
    "    for col in cols:\n",
    "        if col in scalers:\n",
    "            data[col] = scalers[col].transform(data[[col]])\n",
    "    return data\n",
    "\n",
    "# Ajustar los escaladores a las variables no normalizadas en el conjunto de entrenamiento\n",
    "normalizacion_fit(app_train_nonan_le_oh, variables_NO_normalizadas, scaler_type='minmax')\n",
    "\n",
    "# Transformar el conjunto de entrenamiento\n",
    "app_train_nonan_le_oh_norm = normalizacion_transform(app_train_nonan_le_oh, variables_NO_normalizadas)\n",
    "\n",
    "# Verificar los valores nulos y la información del DataFrame transformado\n",
    "print(\"Valores nulos en app_train después de la imputación:\")\n",
    "print(app_train_nonan_le_oh_norm.isnull().sum().sum())\n",
    "print(app_train_nonan_le_oh_norm.info())\n",
    "print(app_train_nonan_le_oh_norm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos el csv tras todo el preprocesamiento\n",
    "#TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/bureau_agg_final.csv\n",
    "#bureau_agg.to_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/bureau_agg_final.csv', index=False)\n",
    "app_train_nonan_le_oh_norm.to_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/application_train_preprocesado_definitivo_v4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg-py3.12",
   "language": "python",
   "name": "tfg-py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
