{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23.5\n",
      "Directorio actual: c:\\Users\\Yeray\\Desktop\\DATA_SCIENCE_ML\\TFG\\NOTEBOOKS\n"
     ]
    }
   ],
   "source": [
    "#Celda para librerías\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "print(np.__version__)\n",
    "from ydata_profiling import ProfileReport\n",
    "import os\n",
    "print(\"Directorio actual:\", os.getcwd())\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display_max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_ID_CURR                     0\n",
      "OBS_30_CNT_SOCIAL_CIRCLE       0\n",
      "WALLSMATERIAL_MODE             0\n",
      "TOTALAREA_MODE                 0\n",
      "HOUSETYPE_MODE                 0\n",
      "                              ..\n",
      "LIVE_REGION_NOT_WORK_REGION    0\n",
      "REG_REGION_NOT_WORK_REGION     0\n",
      "REG_REGION_NOT_LIVE_REGION     0\n",
      "HOUR_APPR_PROCESS_START        0\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR     0\n",
      "Length: 122, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Error al leer solucionado asi v\n",
    "\n",
    "#The error you're encountering is due to the backslashes in the file path being interpreted \n",
    "# as escape characters. To fix this, you can either use raw strings by prefixing the string \n",
    "# with an r, or you can replace the backslashes with forward slashes.\n",
    "\n",
    "url = r\"C:\\Users\\Yeray\\Desktop\\DATA_SCIENCE_ML\\TFG\\DATA\\home-credit-default-risk\\application_train.csv\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "#df.info() #Tenemos 122 columnas, 65 tipo float, 41 tipo int y 16 tipo object\n",
    "descripcion = df.describe() \n",
    "#print(descripcion)\n",
    "\n",
    "#Vamos a ver si hay valores nulos\n",
    "\"\"\"\n",
    "missing_values = df.isnull().sum().sort_values(ascending = False)\n",
    "\n",
    "missing_values_df = missing_values[missing_values > 0]  # Filtra solo las columnas con missing values\n",
    "missing_values_df= missing_values_df.to_frame()  # Convierte la serie en un dataframe\n",
    "missing_values_df = missing_values_df.T  # Transpone la tabla para que las columnas se muestren como filas\n",
    "missing_values_df = missing_values_df.reset_index(drop=True)  # Resetea el índice\n",
    "\n",
    "print(missing_values_df.to_string(index=False))  # Muestra la tabla sin índices\n",
    "\"\"\"\n",
    "\n",
    "#Vamos a tratar estos valores nulos\n",
    "#Primero clasificamos las columnas por tipo de datos\n",
    "#Columnas tipo numérico\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "#Columnas tipo categóricas\n",
    "categoric_columns = df.select_dtypes(include=[object]).columns\n",
    "\n",
    "#Vamos a tratar los valores nulos de las columnas numéricas rellenando con la mediana\n",
    "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median()) \n",
    "#Vamos a tratar los valores nulos de las columnas categóricas rellenando con 0, que representa un valor desconocido\n",
    "df[categoric_columns] = df[categoric_columns].fillna(0)\n",
    "print(df.isnull().sum().sort_values(ascending = False))  #Comprobamos que ya no hay valores nulos\n",
    "\n",
    "dfnomsv=df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas tipo object: Index(['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
      "       'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
      "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE',\n",
      "       'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE',\n",
      "       'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE'],\n",
      "      dtype='object')\n",
      "Valores único en la columna NAME_CONTRACT_TYPE:\n",
      "['Cash loans' 'Revolving loans']\n",
      "Valores único en la columna CODE_GENDER:\n",
      "['M' 'F' 'XNA']\n",
      "Valores único en la columna FLAG_OWN_CAR:\n",
      "['N' 'Y']\n",
      "Valores único en la columna FLAG_OWN_REALTY:\n",
      "['Y' 'N']\n",
      "Valores único en la columna NAME_TYPE_SUITE:\n",
      "['Unaccompanied' 'Family' 'Spouse, partner' 'Children' 'Other_A' 0\n",
      " 'Other_B' 'Group of people']\n",
      "Valores único en la columna NAME_INCOME_TYPE:\n",
      "['Working' 'State servant' 'Commercial associate' 'Pensioner' 'Unemployed'\n",
      " 'Student' 'Businessman' 'Maternity leave']\n",
      "Valores único en la columna NAME_EDUCATION_TYPE:\n",
      "['Secondary / secondary special' 'Higher education' 'Incomplete higher'\n",
      " 'Lower secondary' 'Academic degree']\n",
      "Valores único en la columna NAME_FAMILY_STATUS:\n",
      "['Single / not married' 'Married' 'Civil marriage' 'Widow' 'Separated'\n",
      " 'Unknown']\n",
      "Valores único en la columna NAME_HOUSING_TYPE:\n",
      "['House / apartment' 'Rented apartment' 'With parents'\n",
      " 'Municipal apartment' 'Office apartment' 'Co-op apartment']\n",
      "Valores único en la columna OCCUPATION_TYPE:\n",
      "['Laborers' 'Core staff' 'Accountants' 'Managers' 0 'Drivers'\n",
      " 'Sales staff' 'Cleaning staff' 'Cooking staff' 'Private service staff'\n",
      " 'Medicine staff' 'Security staff' 'High skill tech staff'\n",
      " 'Waiters/barmen staff' 'Low-skill Laborers' 'Realty agents' 'Secretaries'\n",
      " 'IT staff' 'HR staff']\n",
      "Valores único en la columna WEEKDAY_APPR_PROCESS_START:\n",
      "['WEDNESDAY' 'MONDAY' 'THURSDAY' 'SUNDAY' 'SATURDAY' 'FRIDAY' 'TUESDAY']\n",
      "Valores único en la columna ORGANIZATION_TYPE:\n",
      "['Business Entity Type 3' 'School' 'Government' 'Religion' 'Other' 'XNA'\n",
      " 'Electricity' 'Medicine' 'Business Entity Type 2' 'Self-employed'\n",
      " 'Transport: type 2' 'Construction' 'Housing' 'Kindergarten'\n",
      " 'Trade: type 7' 'Industry: type 11' 'Military' 'Services'\n",
      " 'Security Ministries' 'Transport: type 4' 'Industry: type 1' 'Emergency'\n",
      " 'Security' 'Trade: type 2' 'University' 'Transport: type 3' 'Police'\n",
      " 'Business Entity Type 1' 'Postal' 'Industry: type 4' 'Agriculture'\n",
      " 'Restaurant' 'Culture' 'Hotel' 'Industry: type 7' 'Trade: type 3'\n",
      " 'Industry: type 3' 'Bank' 'Industry: type 9' 'Insurance' 'Trade: type 6'\n",
      " 'Industry: type 2' 'Transport: type 1' 'Industry: type 12' 'Mobile'\n",
      " 'Trade: type 1' 'Industry: type 5' 'Industry: type 10' 'Legal Services'\n",
      " 'Advertising' 'Trade: type 5' 'Cleaning' 'Industry: type 13'\n",
      " 'Trade: type 4' 'Telecom' 'Industry: type 8' 'Realtor' 'Industry: type 6']\n",
      "Valores único en la columna FONDKAPREMONT_MODE:\n",
      "['reg oper account' 0 'org spec account' 'reg oper spec account'\n",
      " 'not specified']\n",
      "Valores único en la columna HOUSETYPE_MODE:\n",
      "['block of flats' 0 'terraced house' 'specific housing']\n",
      "Valores único en la columna WALLSMATERIAL_MODE:\n",
      "['Stone, brick' 'Block' 0 'Panel' 'Mixed' 'Wooden' 'Others' 'Monolithic']\n",
      "Valores único en la columna EMERGENCYSTATE_MODE:\n",
      "['No' 0 'Yes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Variables categoricas a cuantitativas\n",
    "# Identificar columnas de tipo object\n",
    "object_columns = dfnomsv.select_dtypes(include=['object']).columns\n",
    "print(\"Columnas tipo object:\", object_columns)\n",
    "\n",
    "#Vamos a ver si podemos convertir las columnas object a numéricas\n",
    "#En este caso no es posible convertir ninguna columna object a numérica\n",
    "\"\"\"\"\n",
    "for col in object_columns:\n",
    "    try:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "        print(f\"Columna {col} convertida a numérica\")\n",
    "    except:\n",
    "        print(f\"No se pudo convertir la columna {col} a numérica\")\n",
    "\"\"\"\n",
    "#Vamos a inspeccionar las columnas que han sido no convertibles para analizarlas más a fondo\n",
    "for col in object_columns:\n",
    "    if not pd.api.types.is_numeric_dtype(dfnomsv[col]):\n",
    "        print(f\"Valores único en la columna {col}:\")\n",
    "        print(dfnomsv[col].unique())\n",
    "        \n",
    "#Codificación one-hot de las columnas categóricas (pd.getdummies)\n",
    "#df2 = pd.get_dummies(df2, columns=object_columns, drop_first=True)\n",
    "#El problema de esto es que nos genera un dataframe con 246 columnas por lo que no lo veo rentable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna NAME_CONTRACT_TYPE convertida a numérica mediante LabelEncoder\n",
      "Columna CODE_GENDER convertida a numérica mediante LabelEncoder\n",
      "Columna FLAG_OWN_CAR convertida a numérica mediante LabelEncoder\n",
      "Columna FLAG_OWN_REALTY convertida a numérica mediante LabelEncoder\n",
      "Columna NAME_TYPE_SUITE convertida a numérica mediante LabelEncoder\n",
      "Columna NAME_INCOME_TYPE convertida a numérica mediante LabelEncoder\n",
      "Columna NAME_EDUCATION_TYPE convertida a numérica mediante LabelEncoder\n",
      "Columna NAME_FAMILY_STATUS convertida a numérica mediante LabelEncoder\n",
      "Columna NAME_HOUSING_TYPE convertida a numérica mediante LabelEncoder\n",
      "Columna OCCUPATION_TYPE convertida a numérica mediante LabelEncoder\n",
      "Columna WEEKDAY_APPR_PROCESS_START convertida a numérica mediante LabelEncoder\n",
      "Columna ORGANIZATION_TYPE convertida a numérica mediante LabelEncoder\n",
      "Columna FONDKAPREMONT_MODE convertida a numérica mediante LabelEncoder\n",
      "Columna HOUSETYPE_MODE convertida a numérica mediante LabelEncoder\n",
      "Columna WALLSMATERIAL_MODE convertida a numérica mediante LabelEncoder\n",
      "Columna EMERGENCYSTATE_MODE convertida a numérica mediante LabelEncoder\n"
     ]
    }
   ],
   "source": [
    "#Vamos a convertirlas mediante LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "#Convertimos previamente todos los valores de las columnas object a string para que labelencoder pueda trabajar con ellas\n",
    "for col in object_columns:\n",
    "    dfnomsv[object_columns] = dfnomsv[object_columns].astype(str)\n",
    "    dfnomsv[col] = label_encoder.fit_transform(dfnomsv[col])\n",
    "    print(f\"Columna {col} convertida a numérica mediante LabelEncoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET                         1.000000\n",
      "DAYS_BIRTH                     0.078239\n",
      "REGION_RATING_CLIENT_W_CITY    0.060893\n",
      "REGION_RATING_CLIENT           0.058899\n",
      "DAYS_LAST_PHONE_CHANGE         0.055218\n",
      "                                 ...   \n",
      "AMT_GOODS_PRICE               -0.039623\n",
      "DAYS_EMPLOYED                 -0.044932\n",
      "EXT_SOURCE_1                  -0.098887\n",
      "EXT_SOURCE_3                  -0.155892\n",
      "EXT_SOURCE_2                  -0.160295\n",
      "Name: TARGET, Length: 122, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Mapa de calor de correlaciones respecto a TARGET para ver la importancia y relaciones de las variables\n",
    "\n",
    "report = ProfileReport(dfnomsv, minimal=True)\n",
    "#display(report)\n",
    "#report.to_file(\"report_minimal.html\")\n",
    "\n",
    "corr_matriz_con_TARGET = dfnomsv.corr()['TARGET'].sort_values(ascending=False)\n",
    "print(corr_matriz_con_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Además de la correlación, vamos a ver la importancia de las variables mediante algunos modelos de ML\t\n",
    "X = dfnomsv.drop('TARGET', axis=1)\n",
    "y= dfnomsv['TARGET']\n",
    "\n",
    "#Entrenamiento del modelo\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1) \n",
    "model.fit(X, y) \n",
    "\n",
    "#Obtener importancia de las característica\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(importances)\n",
    "\n",
    "important_features = importances[importances > 0]\n",
    "X_filtrada = X[important_features.index]\n",
    "\n",
    "print(f\"Dimensiones originales: {X.shape}\")\n",
    "print(f\"Dimensiones después de filtrar características importantes: {X_filtrada.shape}\")\n",
    "\n",
    "#Vamos a eliminar las columnas que mayoritariamente tienen 0's\n",
    "zero_threshhold = 0.95\n",
    "high_zero_cols = [col for col in X_filtrada.columns if (X_filtrada[col] == 0).mean() > zero_threshhold]\n",
    "X_filtrada= X_filtrada.drop(columns=high_zero_cols)\n",
    "\n",
    "print(f\"Dimensiones después de eliminar columnas con más del 95% ceros: {X_filtrada.shape}\")\n",
    "\n",
    "#Division train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Normalizamos los datos\n",
    "scaler = StandardScaler()\n",
    "x_train_escalada = scaler.fit_transform(x_train)\n",
    "x_test_escalada = scaler.transform(x_test)\n",
    "\n",
    "#Random Forest\n",
    "modelrf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "modelrf.fit(x_train_escalada, y_train)\n",
    "y_pred = modelrf.predict(x_test_escalada)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred)  \n",
    "print(f\"ROC AUC del modelo de Random Forest: {roc_auc_rf}\")\n",
    "\n",
    "#Regresión Logística\n",
    "modellr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "modellr.fit(x_train_escalada, y_train)\n",
    "y_pred_lr = modellr.predict_proba(x_test_escalada)[:, 1]\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression ROC-AUC: {roc_auc_lr:.4f}\")\n",
    "\n",
    "# Validación cruzada para Random Forest\n",
    "cv_scores_rf = cross_val_score(modelrf, x_train_escalada, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Random Forest CV ROC-AUC: {np.mean(cv_scores_rf):.4f} ± {np.std(cv_scores_rf):.4f}\")\n",
    "\n",
    "# Validación cruzada para Regresión Logística\n",
    "cv_scores_lr = cross_val_score(modellr, x_train_escalada, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Logistic Regression CV ROC-AUC: {np.mean(cv_scores_lr):.4f} ± {np.std(cv_scores_lr):.4f}\")\n",
    "\n",
    "#Características más importantes\n",
    "print(\"Características más importantes seleccionadas:\")\n",
    "print(important_features.sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
