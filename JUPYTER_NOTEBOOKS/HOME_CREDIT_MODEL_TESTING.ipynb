{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n",
      "Directorio actual: /home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 750 entries, TARGET to LATEST_CREDIT_ACTIVE_CAT_(BUREAU)_Sold\n",
      "dtypes: bool(148), float64(560), int64(42)\n",
      "memory usage: 1.4 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Celda para librerías\n",
    "import sklearn as sk\n",
    "\n",
    "\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(np.__version__)\n",
    "from ydata_profiling import ProfileReport\n",
    "import os\n",
    "print(\"Directorio actual:\", os.getcwd())\n",
    "\n",
    "# Have all columns appear when dataframes are displayed.\n",
    "pd.set_option('display.max_columns', None) \n",
    "# Have 100 rows appear when a dataframe is displayed\n",
    "pd.set_option('display.max_rows', 500)\n",
    "# Display dimensions whenever a dataframe is printed out.\n",
    "pd.set_option('display.show_dimensions', True)\n",
    "\n",
    "#Importando los datos\n",
    "\n",
    "#app_train_def = pd.read_csv(r'C:/Users/Yeray/Desktop/DATA_SCIENCE_ML/Home-Credit-TFG/DATA/application_train_preprocesado_definitivo_v1.csv')\n",
    "#app_train_def_2 = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/application_train_preprocesado_definitivo_v2.csv')\n",
    "#app_train_def_3 = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/application_train_preprocesado_definitivo_v3.csv')\n",
    "app_train_def_4 = pd.read_csv(r'/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/DATA/application_train_preprocesado_definitivo_v4.csv')\n",
    "print(app_train_def_4.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train y Test\n",
    "X = app_train_def_4.drop(columns = ['TARGET'])\n",
    "y = app_train_def_4['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train.columns = X_train.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "X_test.columns = X_test.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos espacio de hiperparámetros para LightGBM\n",
    "space_lightGBM = {\n",
    "    'boosting_type': 'gbdt',  # Fijo\n",
    "    'objective': 'binary',   # Fijo\n",
    "    'metric': 'auc',         # Fijo\n",
    "\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 40, 1), \n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.03),  \n",
    "    'min_child_samples': hp.quniform('min_child_samples', 50, 100, 1),  \n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0.001, 0.02),\n",
    "    'min_gain_to_split': hp.uniform('min_gain_to_split', 0.001, 0.1),\n",
    "    'max_bin': hp.quniform('max_bin', 220, 350, 10),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.15, 0.5),\n",
    "    'max_depth': hp.choice('max_depth', [-1, 3, 5]), \n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1.0), #No admite valores mayores a 1.0\n",
    "    'bagging_freq': hp.quniform('bagging_freq', 1, 15, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 80),  \n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 0.2),  \n",
    "    \n",
    "    'scale_pos_weight': 1,  # Fijo\n",
    "    'is_unbalance': False  # Fijo\n",
    "}\n",
    "\n",
    "Trials_lightGBM_Ligero = Trials()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 400\n",
    "\n",
    "def F_OPT(params):\n",
    "    params['max_bin'] = int(params['max_bin'])\n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['min_child_samples'] = int(params['min_child_samples'])\n",
    "    params['bagging_freq'] = int(params['bagging_freq'])\n",
    "    params['min_child_samples'] = int(params['min_child_samples'])\n",
    "\n",
    "    model = LGBMClassifier(\n",
    "        n_estimators=n_iter,\n",
    "        boosting_type=params['boosting_type'],\n",
    "        objective=params['objective'],\n",
    "        metric=params['metric'],\n",
    "        num_leaves=params['num_leaves'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        min_child_samples=params['min_child_samples'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        min_gain_to_split=params['min_gain_to_split'],\n",
    "        max_bin=params['max_bin'],\n",
    "        feature_fraction=params['feature_fraction'],\n",
    "        max_depth=params['max_depth'],\n",
    "        bagging_fraction=params['bagging_fraction'],\n",
    "        bagging_freq=params['bagging_freq'],\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        scale_pos_weight=params['scale_pos_weight'],\n",
    "        is_unbalance=params['is_unbalance'],\n",
    "        random_state=42)\n",
    "    \n",
    "    cv_Strat = StratifiedKFold(n_splits=5)\n",
    "    auc_lightGBM_Ligero = cross_val_score(model, X_train, y_train, cv=cv_Strat, scoring='roc_auc').mean()\n",
    "    return {'loss': -auc_lightGBM_Ligero, 'status': STATUS_OK}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "best_lightGBM_Ligero = fmin(fn=F_OPT,\n",
    "                            space=space_lightGBM,\n",
    "                            algo=tpe.suggest,\n",
    "                            max_evals=50,\n",
    "                            trials=Trials_lightGBM_Ligero,\n",
    "                            rstate= np.random.default_rng(42)\n",
    ")\n",
    "\n",
    "best_lightGBM_Ligero['num_leaves'] = int(best_lightGBM_Ligero['num_leaves'])\n",
    "best_lightGBM_Ligero['max_bin'] = int(best_lightGBM_Ligero['max_bin'])\n",
    "best_lightGBM_Ligero['min_child_samples'] = int(best_lightGBM_Ligero['min_child_samples'])\n",
    "best_lightGBM_Ligero['bagging_freq'] = int(best_lightGBM_Ligero['bagging_freq'])\n",
    "best_lightGBM_Ligero['min_child_samples'] = int(best_lightGBM_Ligero['min_child_samples'])\n",
    "\n",
    "#print(best_lightGBM_Ligero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/home/yeray/TFG-Home-Credit-Default-Risk/JUPYER_NOTEBOOKS/Trials/Trials_LightGBM_Ligero_v4_server_50_evals_rango_ampliado.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Trials_lightGBM_Ligero, f)\n",
    "with open(\"/home/yeray/TFG-Home-Credit-Default-Risk/JUPYER_NOTEBOOKS/Trials/Trials_LightGBM_Ligero_v4_server_50_evals_rango_ampliado.pkl\", \"rb\") as f:\n",
    "    Trials_lightGBM_Ligero = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostramos los resultados de los trials \n",
    "from tabulate import tabulate\n",
    "\n",
    "def trials_to_dataframe(trials):\n",
    "    \"\"\"\n",
    "    Convierte la info de 'trials' de Hyperopt en un DataFrame \n",
    "    con columnas relevantes (loss, hiperparámetros, etc.).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for trial in trials.trials:\n",
    "        # trial['result']['loss'] -> la métrica\n",
    "        # trial['misc']['vals'] -> diccionario de hiperparámetros propuestos\n",
    "        loss = trial['result']['loss']\n",
    "        vals = trial['misc']['vals']\n",
    "        \n",
    "        # Convertir vals a algo \"plano\"\n",
    "        row = {**vals}\n",
    "        row['loss'] = loss\n",
    "        rows.append(row)\n",
    "    \n",
    "    # df con columnas = keys (vals + 'loss')\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # A veces los hps que eran hp.quniform se quedan en listas => df['num_leaves'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Para usarlo:\n",
    "results_df = trials_to_dataframe(Trials_lightGBM_Ligero)\n",
    "# Ordenamos por 'loss' asc => AUC mayor es 'loss' menor\n",
    "results_df_sorted = results_df.sort_values(by='loss', ascending=True)\n",
    "best_10 = results_df_sorted.head(10)\n",
    "print(tabulate(best_10, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a realizar una selección de variables previa a una optimización más completa y una búsqueda SS\n",
    "# más exhaustiva de hiperparámetros. Para ello, vamos a utilizar Permutation Importance.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "params_ligero = best_lightGBM_Ligero.copy()\n",
    "\n",
    "model_ligero = LGBMClassifier(\n",
    "    n_estimators=n_iter,          # = 200 (tu fase “ligera”)\n",
    "    boosting_type='gbdt',         # Fijo\n",
    "    objective='binary',           # Fijo\n",
    "    metric='auc',                 # Fijo\n",
    "    # Luego pasas los HP que has encontrado en la búsqueda\n",
    "    num_leaves=params_ligero['num_leaves'],\n",
    "    learning_rate=params_ligero['learning_rate'],\n",
    "    min_child_samples=params_ligero['min_child_samples'],\n",
    "    min_child_weight=params_ligero['min_child_weight'],\n",
    "    min_gain_to_split=params_ligero['min_gain_to_split'],\n",
    "    max_bin=params_ligero['max_bin'],\n",
    "    feature_fraction=params_ligero['feature_fraction'],\n",
    "    max_depth=params_ligero['max_depth'],\n",
    "    bagging_fraction=params_ligero['bagging_fraction'],\n",
    "    bagging_freq=params_ligero['bagging_freq'],\n",
    "    reg_lambda=params_ligero['reg_lambda'],\n",
    "    reg_alpha=params_ligero['reg_alpha'],\n",
    "    scale_pos_weight=1,           # Fijo\n",
    "    is_unbalance=False,           # Fijo\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_ligero.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pi = permutation_importance(\n",
    "    estimator=model_ligero,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    scoring='roc_auc',\n",
    "    n_repeats=20,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"pi_lightGBM_Ligero_v3_server_20_reapeats.pkl\", \"wb\") as f:\n",
    "#    pickle.dump(pi, f)\n",
    "\n",
    "with open(\"/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/pi_lightGBM_Ligero_v4_server_20_reapeats.pkl\", \"rb\") as f:\n",
    "    pi = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = X_train.columns\n",
    "importances_mean = pi.importances_mean\n",
    "importances_std = pi.importances_std\n",
    "\n",
    "#Lo unimos en un DF\n",
    "\n",
    "df_pi = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_mean': importances_mean,\n",
    "    'importance_std': importances_std\n",
    "})\n",
    "df_pi.to_csv(\"Permutation_Importance_LightGBM_Ligero_v3_server_20_repeats.csv\", index=False)\n",
    "\n",
    "df_pi_sorted = df_pi.sort_values(by='importance_mean', ascending=False)\n",
    "print(tabulate(df_pi_sorted, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_features_pi = df_pi_sorted[df_pi_sorted['importance_mean'] > 0]\n",
    "subset_features= subset_features_pi['feature'].tolist()\n",
    "X_train_subset = X_train[subset_features]\n",
    "y_train_subset = y_train\n",
    "X_test_subset = X_test[subset_features]\n",
    "y_test_subset = y_test\n",
    "print(X_train_subset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_lightGBM_completo = {\n",
    "    'boosting_type': 'gbdt',  # Fijo\n",
    "    'objective': 'binary',   # Fijo\n",
    "    'metric': 'auc',         # Fijo\n",
    "    #Ajustamos los HP para centrarlos y reducir el rango a los resultados obtenidos anteriormente\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 40, 1), \n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.03),  \n",
    "    'min_child_samples': hp.quniform('min_child_samples', 50, 90, 1),  \n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0.001, 0.01),\n",
    "    'min_gain_to_split': hp.uniform('min_gain_to_split', 0.01, 0.1),\n",
    "    'max_bin': hp.quniform('max_bin', 240, 300, 5),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.2, 0.4),\n",
    "    'max_depth': hp.choice('max_depth', [-1, 3]), \n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1.0),\n",
    "    'bagging_freq': hp.quniform('bagging_freq', 1, 10, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 80),  \n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 0.2),  \n",
    "    \n",
    "    'scale_pos_weight': 1,  # Fijo\n",
    "    'is_unbalance': False  # Fijo\n",
    "}\n",
    "\n",
    "Trials_lightGBM_Completo = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 2000\n",
    "#Vamos a probar ahora a realizar esa búsqueda más extensa pero con seleccionando las variables que parecen tener mayor releveancia\n",
    "def F_OPT_Completa(params):\n",
    "    params['max_bin'] = int(params['max_bin'])\n",
    "    params['min_child_samples'] = int(params['min_child_samples'])\n",
    "    params['bagging_freq'] = int(params['bagging_freq'])\n",
    "    params['min_child_samples'] = int(params['min_child_samples'])\n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "\n",
    "    model = LGBMClassifier(\n",
    "        n_estimators=n_iter,\n",
    "        boosting_type=params['boosting_type'],\n",
    "        objective=params['objective'],\n",
    "        metric=params['metric'],\n",
    "        num_leaves=params['num_leaves'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        min_child_samples=params['min_child_samples'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        min_gain_to_split=params['min_gain_to_split'],\n",
    "        max_bin=params['max_bin'],\n",
    "        feature_fraction=params['feature_fraction'],\n",
    "        max_depth=params['max_depth'],\n",
    "        bagging_fraction=params['bagging_fraction'],\n",
    "        bagging_freq=params['bagging_freq'],\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        scale_pos_weight=params['scale_pos_weight'],\n",
    "        is_unbalance=params['is_unbalance'],\n",
    "        random_state=42\n",
    "        )\n",
    "    \n",
    "    cv_Strat = StratifiedKFold(n_splits=5)\n",
    "    auc_lightGBM_Completo = cross_val_score(model, X_train, y_train, cv=cv_Strat, scoring='roc_auc').mean()\n",
    "    return {'loss': -auc_lightGBM_Completo, 'status': STATUS_OK}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "best_lightGBM_Completo = fmin(fn=F_OPT_Completa,\n",
    "                            space=space_lightGBM_completo,\n",
    "                            algo=tpe.suggest,\n",
    "                            max_evals=100,\n",
    "                            trials=Trials_lightGBM_Completo,\n",
    "                            rstate= np.random.default_rng(42)\n",
    ")\n",
    "best_lightGBM_Completo['max_bin'] = int(best_lightGBM_Completo['max_bin'])\n",
    "best_lightGBM_Completo['min_child_samples'] = int(best_lightGBM_Completo['min_child_samples'])\n",
    "best_lightGBM_Completo['bagging_freq'] = int(best_lightGBM_Completo['bagging_freq'])\n",
    "best_lightGBM_Completo['min_child_samples'] = int(best_lightGBM_Completo['min_child_samples'])\n",
    "best_lightGBM_Completo['num_leaves'] = int(best_lightGBM_Completo['num_leaves'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#with open(\"Trials_LightGBM_Completo_v3_server_100_evals_csv_completo.pkl\", \"wb\") as f:\n",
    "#    pickle.dump(Trials_lightGBM_Completo, f)\n",
    "with open(\"/home/yeray/TFG-Home-Credit-Default-Risk/JUPYTER_NOTEBOOKS/Trials_LightGBM_Completo_v3_server_100_evals_csv_completo.pkl\", \"rb\") as f:\n",
    "    Trials_lightGBM_Completo = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----------------+--------------------+-----------------+-----------+-------------+---------------------+--------------------+---------------------+--------------+-------------+--------------+-----------+\n",
      "|    |   bagging_fraction |   bagging_freq |   feature_fraction |   learning_rate |   max_bin |   max_depth |   min_child_samples |   min_child_weight |   min_gain_to_split |   num_leaves |   reg_alpha |   reg_lambda |      loss |\n",
      "|----+--------------------+----------------+--------------------+-----------------+-----------+-------------+---------------------+--------------------+---------------------+--------------+-------------+--------------+-----------|\n",
      "| 65 |           0.946932 |             10 |           0.202777 |       0.0172655 |       250 |           0 |                  86 |         0.00728436 |           0.0451036 |           33 |   0.0558485 |      35.8496 | -0.779158 |\n",
      "| 70 |           0.918794 |             10 |           0.217858 |       0.0178222 |       250 |           0 |                  82 |         0.00805735 |           0.0170144 |           37 |   0.0271105 |      34.5777 | -0.779113 |\n",
      "| 68 |           0.917398 |             10 |           0.205884 |       0.0181684 |       250 |           0 |                  84 |         0.00919154 |           0.0400489 |           38 |   0.0823074 |      37.0089 | -0.779048 |\n",
      "| 96 |           0.918294 |             10 |           0.209127 |       0.0183172 |       250 |           0 |                  78 |         0.00943802 |           0.0314574 |           24 |   0.0484764 |      25.0775 | -0.779039 |\n",
      "| 40 |           0.837523 |              6 |           0.210913 |       0.0131514 |       300 |           0 |                  88 |         0.00982325 |           0.0694116 |           39 |   0.12488   |      64.5533 | -0.779009 |\n",
      "| 26 |           0.954013 |              9 |           0.252085 |       0.0117938 |       245 |           0 |                  84 |         0.00152312 |           0.0593504 |           38 |   0.0759025 |      50.1859 | -0.778987 |\n",
      "| 76 |           0.856926 |             10 |           0.247041 |       0.0166988 |       260 |           0 |                  82 |         0.00931875 |           0.0294311 |           40 |   0.017507  |      23.2113 | -0.778968 |\n",
      "| 31 |           0.940365 |             10 |           0.201482 |       0.0172915 |       265 |           0 |                  86 |         0.00707585 |           0.0465337 |           33 |   0.0584874 |      33.1656 | -0.778953 |\n",
      "| 73 |           0.896629 |             10 |           0.226197 |       0.0206202 |       250 |           0 |                  83 |         0.00861238 |           0.0340258 |           36 |   0.0550027 |      29.5634 | -0.778945 |\n",
      "| 24 |           0.969212 |              9 |           0.26186  |       0.011809  |       245 |           0 |                  85 |         0.0010419  |           0.0599763 |           37 |   0.0621909 |      50.2739 | -0.778945 |\n",
      "+----+--------------------+----------------+--------------------+-----------------+-----------+-------------+---------------------+--------------------+---------------------+--------------+-------------+--------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "#Mostramos los resultados de los trials \n",
    "from tabulate import tabulate\n",
    "\n",
    "def trials_to_dataframe(trials):\n",
    "    rows = []\n",
    "    for trial in trials.trials:\n",
    "        if 'loss' not in trial['result']:\n",
    "            # saltar este trial\n",
    "            continue\n",
    "\n",
    "        loss = trial['result']['loss']\n",
    "        vals = trial['misc']['vals']\n",
    "        \n",
    "        row = {**vals}\n",
    "        row['loss'] = loss\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Para usarlo:\n",
    "results_df = trials_to_dataframe(Trials_lightGBM_Completo)\n",
    "# Ordenamos por 'loss' asc => AUC mayor es 'loss' menor\n",
    "results_df_sorted = results_df.sort_values(by='loss', ascending=True)\n",
    "best_10 = results_df_sorted.head(10)\n",
    "print(tabulate(best_10, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0451036, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0451036\n",
      "[LightGBM] [Warning] feature_fraction is set=0.202777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.202777\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946932\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0451036, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0451036\n",
      "[LightGBM] [Warning] feature_fraction is set=0.202777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.202777\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946932\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226148\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.639422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 101813\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 699\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432482\n",
      "[LightGBM] [Info] Start training from score -2.432482\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.946932, bagging_freq=10,\n",
       "               feature_fraction=0.202777, is_unbalance=False,\n",
       "               learning_rate=0.0172655, max_bin=250, metric=&#x27;auc&#x27;,\n",
       "               min_child_samples=86, min_child_weight=0.00728436,\n",
       "               min_gain_to_split=0.0451036, n_estimators=2000, num_leaves=33,\n",
       "               objective=&#x27;binary&#x27;, random_state=42, reg_alpha=0.0558485,\n",
       "               reg_lambda=35.8496, scale_pos_weight=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(bagging_fraction=0.946932, bagging_freq=10,\n",
       "               feature_fraction=0.202777, is_unbalance=False,\n",
       "               learning_rate=0.0172655, max_bin=250, metric=&#x27;auc&#x27;,\n",
       "               min_child_samples=86, min_child_weight=0.00728436,\n",
       "               min_gain_to_split=0.0451036, n_estimators=2000, num_leaves=33,\n",
       "               objective=&#x27;binary&#x27;, random_state=42, reg_alpha=0.0558485,\n",
       "               reg_lambda=35.8496, scale_pos_weight=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.946932, bagging_freq=10,\n",
       "               feature_fraction=0.202777, is_unbalance=False,\n",
       "               learning_rate=0.0172655, max_bin=250, metric='auc',\n",
       "               min_child_samples=86, min_child_weight=0.00728436,\n",
       "               min_gain_to_split=0.0451036, n_estimators=2000, num_leaves=33,\n",
       "               objective='binary', random_state=42, reg_alpha=0.0558485,\n",
       "               reg_lambda=35.8496, scale_pos_weight=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'boosting_type': 'gbdt',  # Fijo\n",
    "    'objective': 'binary',   # Fijo\n",
    "    'metric': 'auc',         # Fijo\n",
    "    'num_leaves': 33,        # Fijo\n",
    "    'learning_rate': 0.0172655,   # Fijo\n",
    "    'max_depth': -1,         # Fijo\n",
    "    'bagging_fraction': 0.946932 ,\n",
    "    'bagging_freq': 10,\n",
    "    'feature_fraction':  0.202777 ,\n",
    "    'max_bin': 250,\n",
    "    'min_child_samples': 86,\n",
    "    'min_child_weight': 0.00728436,\n",
    "    'min_gain_to_split':  0.0451036,\n",
    "    'reg_alpha': 0.0558485,\n",
    "    'reg_lambda': 35.8496,\n",
    "    'scale_pos_weight': 1,   # Fijo\n",
    "    'is_unbalance': False,   # Fijo\n",
    "}\n",
    "\n",
    "final_model_lgb = LGBMClassifier(\n",
    "    n_estimators=2000,\n",
    "    boosting_type=best_params['boosting_type'],\n",
    "    objective=best_params['objective'],\n",
    "    metric=best_params['metric'],\n",
    "    num_leaves=best_params['num_leaves'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_bin=best_params['max_bin'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    bagging_fraction=best_params['bagging_fraction'],\n",
    "    bagging_freq=best_params['bagging_freq'],   \n",
    "    feature_fraction=best_params['feature_fraction'],\n",
    "    min_child_samples=best_params['min_child_samples'],\n",
    "    min_child_weight=best_params['min_child_weight'],\n",
    "    min_gain_to_split=best_params['min_gain_to_split'],\n",
    "    reg_alpha=best_params['reg_alpha'],\n",
    "    reg_lambda=best_params['reg_lambda'],\n",
    "    scale_pos_weight=1,\n",
    "    is_unbalance=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0451036, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0451036\n",
      "[LightGBM] [Warning] feature_fraction is set=0.202777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.202777\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.946932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.946932\n",
      "AUC en test: 0.7813628078996644\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = final_model_lgb.predict_proba(X_test)[:, 1]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc_test = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'AUC en test: {auc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-AUC solo con app_train:\n",
    "0.7687757918575168\n",
    "\n",
    "-AUC añadiendo bureau.csv con threshhold de 0.00015:\n",
    "0.7723138876162285\n",
    "\n",
    "-AUC con threshold de 0.0001 y 40 features:\n",
    "0.7741547798044517\n",
    "\n",
    "-AUC con threshold de 0 y ~80 features:\n",
    "0.777795871108371\n",
    "\n",
    "Comienzo de pruebas en server\n",
    "-Realizando Trials con 50 evaluaciones con todo el csv al completo el mejor resultado es de:\n",
    "\n",
    "| 36 |           0.954169 |              4 |           0.316205 |       0.0289061 |       260 |           0 |                  62 |         0.00154331 |           0.0661147 |           39 |  0.134166   |      58.288  | -0.775321 |\n",
    "\n",
    "Si probamos esta misma configuración sobre el test, es decir, HP con 50 evals y todos los features obtenemos: \n",
    "-AUC en test: 0.7807744950085171\n",
    "\n",
    "-Realizando Trials con  100 evaluaciones con un rango más acotado de HP acorde a las pruebas anteriores, además de realizando una selección de variables con un threshold >0 (443 features) obtenemos:\n",
    "\n",
    "|    |   bagging_fraction |   bagging_freq |   feature_fraction |   learning_rate |   max_bin |   max_depth |   min_child_samples |   min_child_weight |   min_gain_to_split |   num_leaves |   reg_alpha |   reg_lambda |      loss |\r\n",
    "|----+--------------------+----------------+--------------------+-----------------+-----------+-------------+---------------------+--------------------+---------------------+--------------+-------------+--------------+-----------|\r\n",
    "| 66 |           0.947598 |              5 |           0.256301 |       0.016433  |       270 |           0 |                  61 |         0.00531868 |           0.0774823 |           37 |   0.053589  |      37.9963 | -0.779018\n",
    "\n",
    "Si probamos esta configuración sobre el test obtenemos:\n",
    "-AUC en test: 0.7806464630531091 ---- Podemos observar que tenemos un resultado minimamente peor, pero puede deberse a fluctuaciones aleatorios, haber excluido alguena feature un poco útil... Aunque al ser una diferencia de ±0.0001–0.0002 de AUC se puede considerar que se encuentra dentro del margen de ruido.\n",
    "\n",
    "-AUC en test: 0.7815232040819751 He puesto nstimators en 2000 en vez de 1000, que se me había pasado cambiarlo\n",
    "\n",
    "Si añadimos los datos de la tabla bureau_balance y realizamos una optimización inicial (50), seleccionamos variables con threshold >0 (478 variables) y luego una optimizacón final (100), obtenemos un resultado de:\n",
    "-AUC en test: 0.780960248215274\n",
    "\n",
    "Si realizamos las pruebas sobre todo el csv sin realizar una selección de variables previa obtenemos:\n",
    "\n",
    "| 65 |           0.946932 |             10 |           0.202777 |       0.0172655 |       250 |           0 |                  86 |         0.00728436 |           0.0451036 |           33 |   0.0558485 |      35.8496 | -0.779158 |\n",
    "\n",
    "Y si realizamos las pruebas sobre el test:\n",
    "-AUC en test: 0.7813628078996644 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg-py3.12",
   "language": "python",
   "name": "tfg-py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
